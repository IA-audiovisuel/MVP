{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b419c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.créer un nouvel env conda à partir du terminal\n",
    "# conda create --name asr_rag python=3.10\n",
    "\n",
    "# 2. activer cet environnement\n",
    "# conda activate asr_rag\n",
    "\n",
    "# 3. installer les dépendences\n",
    "# pip install -r requirements.txt\n",
    "\n",
    "# 4. installer ollama: https://www.ollama.com/download\n",
    "\n",
    "\n",
    "# 5. installer le modème d'OllamaEmbeddings\n",
    "# ollama pull embeddinggemma\n",
    "\n",
    "# 6. créer une clé api sur openrouter pour utiliser des llm gratuitement\n",
    "\n",
    "# 7. mettre votre clé dans le fichier .env (racine du repertoire courant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0299e812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chougar/miniconda3/envs/pathrag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "from pathrag_retriever import create_graphdb, load_existing_graphdb, load_knowledgeGraph_vis\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"./.env\")\n",
    "\n",
    "OPENROUTER_API_KEY=os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "print(OPENROUTER_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebbb31f",
   "metadata": {},
   "source": [
    "#### Création ou chargement d'un graphe existant:\n",
    "> Lorsque vous executer la cellule ci dessous, vous avez 2 options proposées:\n",
    "> 1. Créer un nouveau graphe\n",
    "> 2. Charger un graphe existant\n",
    "> \n",
    "> Un prompt de sélection s'affichera en haut du notebook<br>\n",
    "> Saisir l'action désirée dans le , suivre instructions\n",
    "\n",
    "> Si vous voulez charger un graphe déjà crée et que vous ne savez plus son nom, retrouver le dans le fichier `graphrag_hashes.json` (dans la racine du dossier), attribut `Nom du doc`\n",
    "\n",
    "> Si vous voulez modifier le LLM utilisé pour la création du graphe ou sa lecture, allez dans `pathrag_retriever.py`, sous la ligne 36( Choix du LLM OpenRouter), et prenez un modèle valide sur openrouter (attention à prendre un modèle qui supporte les `structured_outputs`, sur le site openrouter, à filtrer sur le paneau à gauche dans la liste des `Supported parameters`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29614848",
   "metadata": {},
   "source": [
    "#### 1. Créer un graphe, ou charger en un déjà crée\n",
    "Ci dessous un print des noms de docs disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d78ad2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IA conscience\n",
      "L-IA-notre-deuxieme-conscience\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "graph_names=pd.read_json(\"graphrag_hashes.json\")\n",
    "\n",
    "graph_names=graph_names.loc[\"Nom du doc\", :].values.tolist()\n",
    "for n in graph_names:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b63b4a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PathRAG:Logger initialized for working directory: /home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/9fa530c1fd2fc3cee4831f8edcd4822b9353bd24d1dbabef4a12af5a9f4501f5\n",
      "INFO:PathRAG:Load KV llm_response_cache with 0 data\n",
      "INFO:PathRAG:Load KV full_docs with 1 data\n",
      "INFO:PathRAG:Load KV text_chunks with 11 data\n",
      "INFO:PathRAG:Loaded graph from /home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/9fa530c1fd2fc3cee4831f8edcd4822b9353bd24d1dbabef4a12af5a9f4501f5/graph_chunk_entity_relation.graphml with 136 nodes, 120 edges\n",
      "INFO:nano-vectordb:Load (132, 768) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': '/home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/9fa530c1fd2fc3cee4831f8edcd4822b9353bd24d1dbabef4a12af5a9f4501f5/vdb_entities.json'} 132 data\n",
      "INFO:nano-vectordb:Load (120, 768) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': '/home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/9fa530c1fd2fc3cee4831f8edcd4822b9353bd24d1dbabef4a12af5a9f4501f5/vdb_relationships.json'} 120 data\n",
      "INFO:nano-vectordb:Load (11, 768) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': '/home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/9fa530c1fd2fc3cee4831f8edcd4822b9353bd24d1dbabef4a12af5a9f4501f5/vdb_chunks.json'} 11 data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nom de votre graphe est L-IA-notre-deuxieme-conscience\n",
      "\n",
      "        ----------------\n",
      "        #### Graph RAG retriever\n",
      "        Chargement de la base Graph RAG\n",
      "    \n",
      "**✅ Graph RAG chargé**\n",
      "Confirmation LLM read: deepseek/deepseek-chat-v3-0324\n"
     ]
    }
   ],
   "source": [
    "# 1.\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "#==== params de base====\n",
    "\n",
    "# Obligatoire: nom des sources\n",
    "filename=\"audio-text.txt\"\n",
    "doc_name_graph=\"L-IA-notre-deuxieme-conscience\"\n",
    "\n",
    "# Optionnels:\n",
    "# 1. modèle pour création du graph\n",
    "# param 'OPENROUTER_MODEL_graph_creation', par défaut \"deepseek/deepseek-chat-v3-0324\"\n",
    "# passer dans la fonction 'create_graphdb' un autre modèle si vous le souhaitez\n",
    "\n",
    "# 2. modèle pour lecture du graph (questions/réponses)\n",
    "# param 'OPENROUTER_MODEL_graph_read', par défaut \"deepseek/deepseek-chat-v3-0324\"\n",
    "# passer dans la fonction 'load_existing_graphdb' un autre modèle si vous le souhaitez\n",
    "\n",
    "#=======================\n",
    "\n",
    "loader = UnstructuredLoader(filename)\n",
    "\n",
    "txt_docs = loader.load()\n",
    "text=\"\"\n",
    "for doc in txt_docs:\n",
    "    text+=doc.page_content\n",
    "\n",
    "\n",
    "graphrag_action=input(\"Saisir 'C' pour créer un nouveau graphe, 'L' pour charger un graphe existant\")\n",
    "\n",
    "# créer un nouveau graphe\n",
    "messages=None\n",
    "\n",
    "if graphrag_action=='C':\n",
    "    print(f\"Le nom de votre graphe est {doc_name_graph}\")\n",
    "    messages= create_graphdb(\n",
    "        text=text, \n",
    "        doc_name=doc_name_graph, # il faut donner un nom unique permettant d'identifier et charger le graph les prochaines fois\n",
    "    )\n",
    "# charger un graphe existant\n",
    "elif graphrag_action=='L':    \n",
    "    print(f\"Le nom de votre graphe est {doc_name_graph}\")\n",
    "\n",
    "    messages=load_existing_graphdb(\n",
    "        doc_name_graph, \n",
    "        # OPENROUTER_MODEL_graph_read=\"mistralai/mistral-large-2512\"\n",
    "    )\n",
    "else:\n",
    "    print('Option invalide')\n",
    "\n",
    "\n",
    "\n",
    "if messages:\n",
    "    pipeline_args={}\n",
    "    for feedback in messages:\n",
    "        if isinstance(feedback, str):\n",
    "            print(feedback)\n",
    "        elif isinstance(feedback, dict):\n",
    "            pipeline_args[f\"graphrag_pipeline_{doc_name_graph}\"]=feedback[\"pipeline_args\"]\n",
    "            \n",
    "print(\"Confirmation LLM read:\", pipeline_args[f\"graphrag_pipeline_{doc_name_graph}\"][\"llm_graph_QA\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1543579",
   "metadata": {},
   "source": [
    "#### 2. Poser vos questions au graphrag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6de14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:PathRAG:kw_prompt result:\n",
      "INFO:PathRAG:```json\n",
      "{\n",
      "  \"high_level_keywords\": [\"Principaux thèmes\", \"Questions possibles\", \"Analyse de texte\"],\n",
      "  \"low_level_keywords\": [\"Thématiques clés\", \"Interrogations\", \"Compréhension du texte\", \"Discussion\"]\n",
      "}\n",
      "```\n",
      "INFO:PathRAG:Local query uses 40 entites, 15 relations, 3 text units\n",
      "INFO:PathRAG:Global query uses 49 entites, 40 relations, 4 text units\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response all ready\n",
      "### Principaux thèmes du texte\n",
      "\n",
      "1. **L'intelligence artificielle et ses limites**  \n",
      "   Le texte explore largement les capacités et les limites de l'IA, en particulier son incapacité à reproduire la véritable créativité humaine. L'IA est décrite comme excellant dans l'optimisation et la réutilisation de données, mais incapable de générer des pensées originales ou des métaphores, qui sont des marques distinctives de l'intelligence humaine.  \n",
      "\n",
      "2. **La conscience et l'inconscient**  \n",
      "   Une question centrale est de savoir si l'IA peut ou non atteindre une forme de conscience. Les intervenants soulignent que les machines ne peuvent pas comprendre l'inconscient humain, un domaine complexe étudié par la psychanalyse (Lacan, Freud).  \n",
      "\n",
      "3. **L'impact sociétal et professionnel de l'IA**  \n",
      "   Le texte aborde les craintes liées au remplacement des métiers par l'IA, notamment dans le domaine créatif (comme illustré par le concours littéraire entre Hervé Le Tellier et ChatGPT). Laurence Devillers insiste sur l'omniprésence de l'IA dans la vie quotidienne et ses effets sur le travail.  \n",
      "\n",
      "4. **La comparaison historique**  \n",
      "   Valentin Husson replace l'IA dans un contexte plus large, en la comparant à d'autres révolutions technologiques comme l'écriture et l'imprimerie. Il souligne que chaque avancée technologique a suscité des craintes similaires, mais que l'humanité a toujours su s'adapter.  \n",
      "\n",
      "5. **L'éducation et les enjeux futurs**  \n",
      "   Laurence Devillers et d'autres intervenants soulignent l'urgence de mieux éduquer le public sur les véritables enjeux de l'IA, afin d'éviter les illusions marketing et les peurs irrationnelles.  \n",
      "\n",
      "### Questions qui peuvent être posées  \n",
      "\n",
      "1. **Sur les capacités de l'IA**  \n",
      "   - L'IA peut-elle vraiment rivaliser avec la créativité humaine, ou se limite-t-elle à une imitation sophistiquée ?  \n",
      "   - Dans quels domaines l'IA excelle-t-elle, et où échoue-t-elle encore ?  \n",
      "\n",
      "2. **Sur la conscience et l'émotion**  \n",
      "   - Une machine peut-elle un jour développer une forme de conscience ou d'émotion ?  \n",
      "   - Comment distinguer une véritable compréhension de la simple reproduction algorithmique ?  \n",
      "\n",
      "3. **Sur l'impact social**  \n",
      "   - Quels métiers sont les plus menacés par l'IA, et comment les humains peuvent-ils s'adapter ?  \n",
      "   - L'IA va-t-elle renforcer ou réduire les inégalités sociales ?  \n",
      "\n",
      "4. **Sur l'éthique et la régulation**  \n",
      "   - Comment éviter l'anthropomorphisation excessive des machines et les illusions marketing autour de l'IA ?  \n",
      "   - Faut-il encadrer juridiquement le développement de l'IA pour protéger les emplois et la vie privée ?  \n",
      "\n",
      "5. **Sur l'histoire et la philosophie**  \n",
      "   - Les craintes actuelles face à l'IA sont-elles similaires à celles suscitées par les révolutions technologiques passées ?  \n",
      "   - L'IA remet-elle en question la singularité de l'intelligence humaine, ou la renforce-t-elle au contraire ?  \n",
      "\n",
      "Ces thèmes et questions reflètent les débats actuels sur l'IA, mêlant inquiétudes, espoirs et réflexions philosophiques."
     ]
    }
   ],
   "source": [
    "from PathRAG import QueryParam\n",
    "import asyncio\n",
    "\n",
    "def stream_pathRAG_response(stream_resp):\n",
    "    async def stream_response():        \n",
    "        # Process the async generator\n",
    "        async for chunk in stream_resp:\n",
    "            print(chunk or \"\", end=\"\")\n",
    "\n",
    "\n",
    "    # Run in Streamlit's existing event loop\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(stream_response())\n",
    "\n",
    "# question=\"résume ce texte dans sa langue source\"\n",
    "question = \"Quels sont les principaux thèmes de ce texte et les questions qui peuvent être posées ?\"\n",
    "# question=\"Qui sont les intervenants dans ce texte ? \"\n",
    "\n",
    "resp=pipeline_args[f\"graphrag_pipeline_{doc_name_graph}\"][\"rag\"].query(\n",
    "    query= question, \n",
    "    param=QueryParam(mode=\"hybrid\", stream=True,)\n",
    ")\n",
    "\n",
    "stream_pathRAG_response(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f595f8",
   "metadata": {},
   "source": [
    "============================\n",
    "### RAG vectoriel\n",
    "1. Embedding du document -> renseigner le nom de votre fichier dans `filename` et le nom de votre DB dans `doc_name_hybrid`\n",
    "2. Setup du retriever / reranker / llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76565f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 30 documents from audio-text.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de chuncks: 372\n"
     ]
    }
   ],
   "source": [
    "#1\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.retrievers import TFIDFRetriever\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "# chargement et fragmentation du doc\n",
    "## Nom du doc à traiter\n",
    "filename=\"audio-text.txt\"\n",
    "\n",
    "## Nom pour la base vectorielle\n",
    "doc_name_hybrid=\"L-IA-notre-deuxieme-conscience_sample\" # nom de doc significatif\n",
    "\n",
    "\n",
    "\n",
    "#========= choix du modèle d'embedding\n",
    "\"\"\"\n",
    "    Le modèle choisi impacte la qualité du retriever, mais aussi le temps de traitement\n",
    "    Si le déploiement est prévu sur une VM limitée, un modèle plus petit est nécessaire\n",
    "    Explorer les comparatifs: https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "\"\"\"\n",
    "# Utiliser OllamaEmbeddings avec le modèle local \"embeddinggemma\"\n",
    "embeddings = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "\n",
    "\n",
    "# loader = UnstructuredFileLoader(filename)\n",
    "loader = UnstructuredLoader(filename)\n",
    "\n",
    "txt_doc = loader.load()\n",
    "print(f\"Loaded {len(txt_doc)} documents from {filename}\")\n",
    "\n",
    "\n",
    "#======== choix des paramètres de fragmentation\n",
    "\"\"\"\n",
    "    la taille du chunck_size est très important dans l'accès à une info précise\n",
    "    une plus petite taille permet de cibler de courts passages contenant l'info nécessaire à des réponses précises:\n",
    "        * lieu du projet\n",
    "        * dates du projet\n",
    "        * budget ...    \n",
    "    l'envoi de passages plus courts au llm évite une dispertion de son attention\n",
    "\"\"\"\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(txt_doc)\n",
    "\n",
    "# Filter out complex metadata (e.g., lists, dicts)\n",
    "docs = [Document(doc.page_content) for doc in docs]\n",
    "\n",
    "\n",
    "# Conversion des docs en embeddings \n",
    "chroma_db = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=f'./storage/vector_scores/{doc_name_hybrid.replace(\" \",\"_\")}',\n",
    "    collection_name=doc_name_hybrid.replace(\" \",\"_\")\n",
    ")\n",
    "\n",
    "retriever=chroma_db.as_retriever()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ...existing code...\n",
    "all_docs = chroma_db.get()\n",
    "print(\"Nb de chuncks:\", len(all_docs['documents']))  # This will print the total number of docs stored\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6f9772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nathan Devert]: France Culture. [Nathan Devert]: France Culture, sans préjuger. Nathan Devert. [Nathan Devert]: Comment expliquer les progrès phénoménaux que semble avoir accompli l'intelligence artificielle au cours de ces dernières années ? Depuis l'apparition de ChatGPT en novembre 2022, rapidement suivi par d'autres agents conversationnels, cette révolution technologique aux multiples aspects, paraît désormais capable d'exécuter de nombreuses tâches intellectuelles sur lesquelles l'esprit humain pensait jusqu'alors exercer un monopole. Écrire des articles, synthétiser des documents, traiter des données dans n'importe quel domaine, diagnostiquer une maladie, rédiger une dissertation, ou pourquoi pas, un scénario de film. Non contente de révolutionner le monde du travail, ses prouesses stupéfiantes de la technique soulèvent une interrogation majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et \n",
      "taille: 999\n",
      "=============\n",
      "stupéfiantes de la technique soulèvent une interrogation majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans n'importe quelle machine, voir, comme s'inquiètent ou exultent certains, que l'IA sera un jour en mesure de remplacer notre conscience. À moins qu'il ne faille poser cette question à l'envers. Comment se fait-il que la machine puisse imiter les œuvres de de notre esprit ? Comment est-il possible en d'autres termes que notre vie mentale se révèle comme mécanisable, au même titre que nos facultés manuelles ? L'intelligence artificielle ne doit-elle pas sa capacité d'imitation au fait qu'elle a été théorisée, inventée, développée d'après une certaine représentation, peut-être incomplète ou biaisée, des ressorts de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre \n",
      "taille: 998\n",
      "=============\n",
      "représentation, peut-être incomplète ou biaisée, des ressorts de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième conscience. À l'occasion de la fête de la Science, j'aurai le plaisir d'en débattre sans préjuger aux côtés du mathématicien et philosophe Daniel Andler, de la professeur en intelligence artificielle et chercheuse Laurence Devillers et du philosophe Valentin Husson. [Narrateur radio]: France Culture, sans préjuger. Nathan Devert. [Nathan Devert]: Bonjour Laurence Devillers. [Laurence Devillers]: Bonjour. [Nathan Devert]: Vous êtes professeur en intelligence artificielle à Sorbonne Université, chercheuse au CNRS, auteur de \"L'IA, ange ou démon\" paru en 2025 aux éditions du Serge et présidente de la Fondation Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devert]: Vous êtes mathématicien, philosophe, professeur \n",
      "taille: 999\n",
      "=============\n",
      "paru en 2025 aux éditions du Serge et présidente de la Fondation Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devert]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des Sciences morales et politiques et auteur de \"Intelligence artificielle, intelligence humaine, la double énigme\" aux éditions Gallimard et bonjour Valentin Husson. [Valentin Husson]: Vous êtes philosophe et auteur de \"Folle résentimentale, petite philosophie des trolls\" chez Philosophie Magazine éditeur qui vient de paraître. Alors pour commencer cette cette discussion sur l'intelligence artificielle, je voulais vous soumettre une histoire qui a eu lieu récemment en mars 2025. Le Nouvel Obs a décidé d'organiser un concours littéraire entre deux auteurs, entre guillemets. Alors le premier était Hervé Le Tellier, pris Goncourt 2020, auteur de du célèbre roman l'anomalie et le deuxième était l'intelligence artificielle et plus précisément \n",
      "taille: 994\n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "for c in all_docs[\"documents\"][:4]:\n",
    "    print(c, f\"\\ntaille: {len(c)}\" \"\\n=============\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84137027",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.schema.document import Document\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "class RAG_hybrid():\n",
    "    def __init__(self, model):\n",
    "        self.model=model\n",
    "        self.retrieved_docs=[]\n",
    "        self.semantic_retriever_topK=40\n",
    "        self.sparse_retriever_topK=40\n",
    "        self.reranker_topK=25\n",
    "        self.history=[]\n",
    "        self.llm_client = AsyncOpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=OPENROUTER_API_KEY,\n",
    "        )\n",
    "        self.reranker_llm=\"mistralai/mistral-small-3.1-24b-instruct\"\n",
    "        self.doc_name_hybrid=doc_name_hybrid\n",
    "        self.reranker_score_thresh=5\n",
    "        self.reranked_doc=[]\n",
    "\n",
    "    def semanticRetriever(self):\n",
    "        # 1. Semantic Retriever (Chroma + OllamaEmbeddings)\n",
    "        embeddings = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "        if self.doc_name_hybrid == 'None':\n",
    "            return \"Error: fournir le nom du document\"\n",
    "        \n",
    "        chroma_db = Chroma(\n",
    "            persist_directory=f'./storage/vector_scores/{self.doc_name_hybrid.replace(\" \",\"_\")}',\n",
    "            collection_name=self.doc_name_hybrid.replace(\" \",\"_\"),\n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "\n",
    "        semantic_retriever=chroma_db.as_retriever(search_type=\"mmr\", k=self.semantic_retriever_topK)\n",
    "\n",
    "        self.chroma_db=chroma_db\n",
    "        self.semantic_retriever=semantic_retriever\n",
    "\n",
    "        return \"Success: ChromaDB setup avec succes\"\n",
    "    \n",
    "    def sparseRetriever(self):\n",
    "        # 2. Sparse Retriever (TF-IDF)\n",
    "\n",
    "        # Récupérer TOUS les documents depuis Chroma\n",
    "        all_data = self.chroma_db.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "        # Convertir en liste de `Document` objects pour LangChain\n",
    "        docs = [\n",
    "            Document(page_content=text, metadata=meta or {})  # <-- Si meta est None, on met {}\n",
    "            for text, meta in zip(all_data[\"documents\"], all_data[\"metadatas\"])\n",
    "        ]\n",
    "\n",
    "        # Créer le retriever TF-IDF\n",
    "        sparse_retriever = TFIDFRetriever.from_documents(\n",
    "            documents=docs,\n",
    "            k=self.sparse_retriever_topK,\n",
    "            tfidf_params={\"min_df\": 1, \"ngram_range\": (1, 2)}\n",
    "        )\n",
    "\n",
    "        self.sparse_retriever= sparse_retriever\n",
    "    \n",
    "    def ensembleRetriever(self):\n",
    "        # 3. Ensemble Retriever (Semantic + Sparse)\n",
    "        ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[self.semantic_retriever, self.sparse_retriever],\n",
    "            weights=[0.5, 0.5]\n",
    "        )\n",
    "\n",
    "        self.ensemble_retriever=ensemble_retriever\n",
    "\n",
    "    async def reranker(self, results, query):\n",
    "\n",
    "\n",
    "        async def llm_eval(doc, query):\n",
    "            system_prompt=\"\"\"\n",
    "                You're an expert assistant in reranking documents against a question.\n",
    "                Your role is to compare the question with a document and give a score from 0 to 10, where:\n",
    "                0=document out of context, unable to answer the question\n",
    "                10=highly relevant document, able to answer the question\n",
    "                                \n",
    "                The expected final output is the score in json format\n",
    "                Example:\n",
    "                ```json{\"score\": 5}```\n",
    "                \n",
    "                It is very IMPORTANT to follow these instructions:\n",
    "                * Reply only with the score\n",
    "                * Always end your answer with this json format\n",
    "            \"\"\"\n",
    "            response = await self.llm_client.chat.completions.create(\n",
    "                model=self.reranker_llm,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                        La question est: {query}\\n Le document à évaluer est le suivant\\n: {doc}\n",
    "                    \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"audio-hybrid-rag-reranker\",  # Optional for rankings\n",
    "                    \"X-Title\": \"audio-hybrid-rag-reranker\",  # Optional for rankings\n",
    "                },\n",
    "                extra_body={\n",
    "                    \"user\": \"audio-hybrid-rag-reranker\"\n",
    "                }                \n",
    "            )\n",
    "            # Post-process to extract only the JSON part if extra text is present\n",
    "            content = response.choices[0].message.content\n",
    "            # Try to extract the JSON block if the model adds extra text\n",
    "            match = re.search(r\"\\{.*?\\}\", content, re.DOTALL)\n",
    "            if match:\n",
    "                content = match.group(0)\n",
    "\n",
    "            # extract score\n",
    "            score=None\n",
    "            try:\n",
    "                score=content.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "                \n",
    "                score= json.loads(score)\n",
    "                score=score[\"score\"]\n",
    "            except Exception as e:\n",
    "                print(e)                \n",
    "            \n",
    "            return {\"content\": doc, \"score\": score}\n",
    "\n",
    "\n",
    "        tasks=[llm_eval(doc.page_content, query) for doc in results]\n",
    "        scored_docs= await asyncio.gather(*tasks)\n",
    "        i=1\n",
    "\n",
    "        for doc in scored_docs:\n",
    "          \n",
    "            print(f'chunk {i} score: {doc[\"score\"]}')\n",
    "            i+=1\n",
    "\n",
    "        filtred_docs=[d for d in scored_docs if int(d[\"score\"])>=self.reranker_score_thresh]\n",
    "        # print(f\"scored docs; \\n{scored_docs}\")\n",
    "        self.reranked_doc=filtred_docs\n",
    "\n",
    "        return filtred_docs[:self.reranker_topK]\n",
    "\n",
    "    async def ask_llm(self, query):\n",
    "        # 5. Final processing step with an LLM (e.g., OpenAI via OpenRouter)\n",
    "\n",
    "        # init retrievers\n",
    "        status=self.semanticRetriever()\n",
    "        if \"Error\" in status:\n",
    "            return status\n",
    "        \n",
    "        self.sparseRetriever()\n",
    "        self.ensembleRetriever()\n",
    "\n",
    "        # retrieve relevant docs\n",
    "        results = self.ensemble_retriever.get_relevant_documents(query)\n",
    "        print(f\"Nb of retrieved docs: {len(results)}\")\n",
    "\n",
    "        # rerank\n",
    "        scored_results=await self.reranker(results, query)\n",
    "        \n",
    "        # Concatenate retrieved documents for context\n",
    "        context = \"\\n\".join([f\"Fragment: \\n{doc['content']}\\n\" for doc in scored_results])\n",
    "\n",
    "        print(f\"Context lenght: {len(context.split(' '))} words\")\n",
    "        llm_prompt = f\"\"\"\n",
    "            Answer the question based **only** on the provided context.  \n",
    "\n",
    "            - If the context contains enough information to provide a complete or partial answer, use it to formulate a detailed and factual response.  \n",
    "            - If the context lacks relevant information, respond with: \"I don't know.\"  \n",
    "\n",
    "            ### **Context:**  \n",
    "            {context}  \n",
    "\n",
    "            ### **Question:**  \n",
    "            {query}  \n",
    "\n",
    "            ### **Answer:**  \n",
    "            Provide a clear, factual, and well-structured response based on the available context. Avoid speculation or adding external knowledge.  \n",
    "        \"\"\"\n",
    "\n",
    "        llm_completion = await self.llm_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in document Q/A and document synthesis\"},\n",
    "                {\"role\": \"user\", \"content\": llm_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            stream=True,\n",
    "            extra_headers={\n",
    "                \"HTTP-Referer\": \"audio-hybrid-rag-generation\",  # Optional for rankings\n",
    "                \"X-Title\": \"audio-hybrid-rag-generation\",  # Optional for rankings\n",
    "            },\n",
    "            extra_body={\n",
    "                \"user\": \"audio-hybrid-rag-generation\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "        final_answer = \"\"\n",
    "        print(\"Réponse:\\n=========\")\n",
    "        async for chunk in llm_completion:\n",
    "            if hasattr(chunk.choices[0].delta, \"content\") and chunk.choices[0].delta.content:\n",
    "                final_answer += chunk.choices[0].delta.content\n",
    "                print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "        \n",
    "        self.history+=[\n",
    "            {\"role\": \"user\", 'content': query},\n",
    "            {\"role\": \"assistant\", \"content\": final_answer}\n",
    "        ]\n",
    "        \n",
    "        return final_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a224490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_359139/1895004996.py:33: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(model=\"embeddinggemma\")\n",
      "/tmp/ipykernel_359139/1895004996.py:37: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  chroma_db = Chroma(\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "/tmp/ipykernel_359139/1895004996.py:163: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = self.ensemble_retriever.get_relevant_documents(query)\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionQueryEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of retrieved docs: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 score: 8\n",
      "chunk 2 score: 3\n",
      "chunk 3 score: 3\n",
      "chunk 4 score: 3\n",
      "chunk 5 score: 3\n",
      "chunk 6 score: 3\n",
      "chunk 7 score: 6\n",
      "chunk 8 score: 7\n",
      "chunk 9 score: 3\n",
      "chunk 10 score: 6\n",
      "chunk 11 score: 2\n",
      "chunk 12 score: 3\n",
      "chunk 13 score: 3\n",
      "chunk 14 score: 2\n",
      "chunk 15 score: 3\n",
      "Context lenght: 459 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse:\n",
      "=========\n",
      "Les principaux thèmes de ce texte sont :  \n",
      "\n",
      "1. **L'inconscient numérique** : L'idée d'un \"deuxième inconscient\" propre à l'ère numérique, distinct de l'inconscient psychanalytique ou idéologique, lié au traitement des données par l'intelligence artificielle. La question posée est : *L'IA est-elle notre nouvel inconscient ?*  \n",
      "\n",
      "2. **Le rêve prométhéen de l'IA** : La quête de créer une machine réellement intelligente, au sens humain, et les défis philosophiques que cela soulève. La question associée est : *Où en est-on, 70 ans après, dans la réalisation de ce rêve ?*  \n",
      "\n",
      "3. **Les limites de la compréhension et de la conscience** : Un débat sur la nature de la compréhension et de la conscience, notamment à travers des questions comme le test de Turing. Les questions soulevées incluent : *Une machine peut-elle vraiment comprendre ? Comment définir la conscience ou la compréhension chez l'humain ou la machine ?*  \n",
      "\n",
      "4. **Les controverses philosophiques** : Les divergences d'opinions sur les capacités de l'IA, entre ceux qui jugent cela impossible (car une machine \"ne pense pas\") et ceux qui remettent en cause les définitions mêmes de la pensée ou de la compréhension.  \n",
      "\n",
      "Le texte invite ainsi à des réflexions sur la nature de l'intelligence, les frontières entre humain et machine, et les implications éthiques ou conceptuelles de l'IA."
     ]
    }
   ],
   "source": [
    "# rag_hybrid=RAG_hybrid(model=\"mistralai/mistral-small-3.2-24b-instruct\")\n",
    "# rag_hybrid=RAG_hybrid(model=\"mistralai/mistral-large-2512\")\n",
    "rag_hybrid=RAG_hybrid(model=\"deepseek/deepseek-chat-v3-0324\")\n",
    "# 4. Ask a question\n",
    "question = \"Quels sont les principaux thèmes de ce texte et les questions qui peuvent être posées ?\"\n",
    "results = await rag_hybrid.ask_llm(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc293fe8",
   "metadata": {},
   "source": [
    "#### Optimisation de l'IR avec HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5cede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.schema.document import Document\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "class RAG_hybrid_HyDE():\n",
    "    def __init__(self, model):\n",
    "        self.model=model\n",
    "        self.retrieved_docs=[]\n",
    "        self.semantic_retriever_topK=40\n",
    "        self.sparse_retriever_topK=40\n",
    "        self.reranker_topK=25\n",
    "        self.history=[]\n",
    "        self.llm_client = AsyncOpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=OPENROUTER_API_KEY,\n",
    "        )\n",
    "        self.reranker_llm=\"mistralai/mistral-small-3.1-24b-instruct\"\n",
    "        self.doc_name_hybrid=doc_name_hybrid\n",
    "        self.reranker_score_thresh=5\n",
    "        self.reranked_doc=[]\n",
    "\n",
    "    async def generate_hypothetical_document(self, query):\n",
    "        system_prompt = \"\"\"\n",
    "            You are an expert assistant.\n",
    "            Given a question, generate a hypothetical document\n",
    "            that would correctly answer the question.\n",
    "            The document must be factual, neutral, and informative.\n",
    "            Do not mention that this is a hypothetical document.\n",
    "        \"\"\"\n",
    "\n",
    "        response = await self.llm_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": query}\n",
    "            ],\n",
    "            temperature=0,\n",
    "            extra_headers={\n",
    "                \"HTTP-Referer\": \"audio-hyde-rag\",  # Optional for rankings\n",
    "                \"X-Title\": \"audio-hyde-rag\",  # Optional for rankings\n",
    "            },\n",
    "            extra_body={\n",
    "                \"user\": \"audio-hyde-rag-query-document\"\n",
    "            }                            \n",
    "        )\n",
    "\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "\n",
    "    def semanticRetriever(self):\n",
    "        # 1. Semantic Retriever (Chroma + OllamaEmbeddings)\n",
    "        embeddings = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "        if self.doc_name_hybrid == 'None':\n",
    "            return \"Error: fournir le nom du document\"\n",
    "        \n",
    "        chroma_db = Chroma(\n",
    "            persist_directory=f'./storage/vector_scores/{self.doc_name_hybrid.replace(\" \",\"_\")}',\n",
    "            collection_name=self.doc_name_hybrid.replace(\" \",\"_\"),\n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "\n",
    "        semantic_retriever=chroma_db.as_retriever(search_type=\"mmr\", k=self.semantic_retriever_topK)\n",
    "\n",
    "        self.chroma_db=chroma_db\n",
    "        self.semantic_retriever=semantic_retriever\n",
    "\n",
    "        return \"Success: ChromaDB setup avec succes\"\n",
    "    \n",
    "    def sparseRetriever(self):\n",
    "        # 2. Sparse Retriever (TF-IDF)\n",
    "\n",
    "        # Récupérer TOUS les documents depuis Chroma\n",
    "        all_data = self.chroma_db.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "        # Convertir en liste de `Document` objects pour LangChain\n",
    "        docs = [\n",
    "            Document(page_content=text, metadata=meta or {})  # <-- Si meta est None, on met {}\n",
    "            for text, meta in zip(all_data[\"documents\"], all_data[\"metadatas\"])\n",
    "        ]\n",
    "\n",
    "        # Créer le retriever TF-IDF\n",
    "        sparse_retriever = TFIDFRetriever.from_documents(\n",
    "            documents=docs,\n",
    "            k=self.sparse_retriever_topK,\n",
    "            tfidf_params={\"min_df\": 1, \"ngram_range\": (1, 2)}\n",
    "        )\n",
    "\n",
    "        self.sparse_retriever= sparse_retriever\n",
    "    \n",
    "    def ensembleRetriever(self):\n",
    "        # 3. Ensemble Retriever (Semantic + Sparse)\n",
    "        ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[self.semantic_retriever, self.sparse_retriever],\n",
    "            weights=[0.5, 0.5]\n",
    "        )\n",
    "\n",
    "        self.ensemble_retriever=ensemble_retriever\n",
    "\n",
    "    async def reranker(self, results, query):\n",
    "\n",
    "\n",
    "        async def llm_eval(doc, query):\n",
    "            system_prompt=\"\"\"\n",
    "                You're an expert assistant in reranking documents against a question.\n",
    "                Your role is to compare the question with a document and give a score from 0 to 10, where:\n",
    "                0=document out of context, unable to answer the question\n",
    "                10=highly relevant document, able to answer the question\n",
    "                                \n",
    "                The expected final output is the score in json format\n",
    "                Example:\n",
    "                ```json{\"score\": 5}```\n",
    "                \n",
    "                \n",
    "                It is very IMPORTANT to follow these instructions:\n",
    "                * Reply only with the score\n",
    "                * Always end your answer with this json format\n",
    "            \"\"\"\n",
    "            response = await self.llm_client.chat.completions.create(\n",
    "                model=self.reranker_llm,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"\"\"\n",
    "                        La question est: {query}\\n Le document à évaluer est le suivant\\n: {doc}\n",
    "                    \"\"\"\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0,\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"audio-hyde-rag-reranker\",  # Optional for rankings\n",
    "                    \"X-Title\": \"audio-hyde-rag-reranker\",  # Optional for rankings\n",
    "                },\n",
    "                extra_body={\n",
    "                    \"user\": \"audio-hyde-rag-reranker\"\n",
    "                }                \n",
    "            )\n",
    "            \n",
    "            # Post-process to extract only the JSON part if extra text is present\n",
    "            content = response.choices[0].message.content\n",
    "            # Try to extract the JSON block if the model adds extra text\n",
    "            match = re.search(r\"\\{.*?\\}\", content, re.DOTALL)\n",
    "            if match:\n",
    "                content = match.group(0)\n",
    "\n",
    "            # extract score\n",
    "            score=None\n",
    "            try:\n",
    "                score=content.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "                \n",
    "                score= json.loads(score)\n",
    "                score=score[\"score\"]\n",
    "            except Exception as e:\n",
    "                print(e)                \n",
    "            \n",
    "            return {\"content\": doc, \"score\": score}\n",
    "\n",
    "\n",
    "        tasks=[llm_eval(doc.page_content, query) for doc in results]\n",
    "        scored_docs= await asyncio.gather(*tasks)\n",
    "        i=1\n",
    "\n",
    "        for doc in scored_docs:\n",
    "          \n",
    "            print(f'chunk {i} score: {doc[\"score\"]}')\n",
    "            i+=1\n",
    "\n",
    "        filtred_docs=[d for d in scored_docs if int(d[\"score\"])>=self.reranker_score_thresh]\n",
    "        # print(f\"scored docs; \\n{scored_docs}\")\n",
    "        self.reranked_doc=filtred_docs\n",
    "\n",
    "        return filtred_docs[:self.reranker_topK]\n",
    "\n",
    "    async def ask_llm(self, query):\n",
    "        # 5. Final processing step with an LLM (e.g., OpenAI via OpenRouter)\n",
    "\n",
    "        # init retrievers\n",
    "        status=self.semanticRetriever()\n",
    "        if \"Error\" in status:\n",
    "            return status\n",
    "        \n",
    "        self.sparseRetriever()\n",
    "        self.ensembleRetriever()\n",
    "        \n",
    "        # HyDE\n",
    "        context=\"\"\n",
    "        for c in all_docs[\"documents\"][:6]:\n",
    "            context+=c\n",
    "        context_and_query=f\"\"\"\n",
    "            The query:\n",
    "            {query}\n",
    "\n",
    "            The context of the corpus:\n",
    "            {context}\n",
    "\n",
    "            Now generate a corresponding hypothetical document\n",
    "        \"\"\"\n",
    "        hypothetical_doc = await self.generate_hypothetical_document(context_and_query)\n",
    "\n",
    "        self.hypothetical_document=hypothetical_doc\n",
    "\n",
    "        # double retireval (relevant docs to query + HyDE)\n",
    "        results_query = self.ensemble_retriever.get_relevant_documents(query)\n",
    "        results_hyde = self.ensemble_retriever.get_relevant_documents(hypothetical_doc)\n",
    "\n",
    "        # Fusion + déduplication\n",
    "        all_results = {doc.page_content: doc for doc in results_query + results_hyde}\n",
    "        results = list(all_results.values())\n",
    "\n",
    "        print(f\"Nb of retrieved docs: {len(results)}\")\n",
    "\n",
    "        # rerank\n",
    "        scored_results=await self.reranker(results, query)\n",
    "        \n",
    "        # Concatenate retrieved documents for context\n",
    "        context = \"\\n\".join([f\"Fragment: \\n{doc['content']}\\n\" for doc in scored_results])\n",
    "\n",
    "        print(f\"Context lenght: {len(context.split(' '))} words\")\n",
    "        llm_prompt = f\"\"\"\n",
    "            Answer the question based **only** on the provided context.  \n",
    "\n",
    "            - If the context contains enough information to provide a complete or partial answer, use it to formulate a detailed and factual response.  \n",
    "            - If the context lacks relevant information, respond with: \"I don't know.\"  \n",
    "\n",
    "            ### **Context:**  \n",
    "            {context}  \n",
    "\n",
    "            ### **Question:**  \n",
    "            {query}  \n",
    "\n",
    "            ### **Answer:**  \n",
    "            Provide a clear, factual, and well-structured response based on the available context. Avoid speculation or adding external knowledge.  \n",
    "        \"\"\"\n",
    "\n",
    "        llm_completion = await self.llm_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in document Q/A and document synthesis\"},\n",
    "                {\"role\": \"user\", \"content\": llm_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            stream=True,\n",
    "            extra_headers={\n",
    "                \"HTTP-Referer\": \"audio-hyde-rag-generation\",  # Optional for rankings\n",
    "                \"X-Title\": \"audio-hyde-rag-generation\",  # Optional for rankings\n",
    "            },\n",
    "            extra_body={\n",
    "                \"user\": \"audio-hyde-rag-generation\"\n",
    "            }                            \n",
    "        )\n",
    "\n",
    "        final_answer = \"\"\n",
    "        print(\"Réponse:\\n=========\")\n",
    "        async for chunk in llm_completion:\n",
    "            if hasattr(chunk.choices[0].delta, \"content\") and chunk.choices[0].delta.content:\n",
    "                final_answer += chunk.choices[0].delta.content\n",
    "                print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "        \n",
    "        self.history+=[\n",
    "            {\"role\": \"user\", 'content': query},\n",
    "            {\"role\": \"assistant\", \"content\": final_answer}\n",
    "        ]\n",
    "        \n",
    "        return final_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfdd5055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of retrieved docs: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 score: 8\n",
      "chunk 2 score: 3\n",
      "chunk 3 score: 3\n",
      "chunk 4 score: 3\n",
      "chunk 5 score: 3\n",
      "chunk 6 score: 2\n",
      "chunk 7 score: 6\n",
      "chunk 8 score: 8\n",
      "chunk 9 score: 3\n",
      "chunk 10 score: 6\n",
      "chunk 11 score: 2\n",
      "chunk 12 score: 3\n",
      "chunk 13 score: 3\n",
      "chunk 14 score: 2\n",
      "chunk 15 score: 3\n",
      "chunk 16 score: 3\n",
      "chunk 17 score: 6\n",
      "chunk 18 score: 8\n",
      "chunk 19 score: 2\n",
      "chunk 20 score: 7\n",
      "chunk 21 score: 3\n",
      "chunk 22 score: 3\n",
      "chunk 23 score: 8\n",
      "chunk 24 score: 3\n",
      "chunk 25 score: 7\n",
      "chunk 26 score: 7\n",
      "chunk 27 score: 2\n",
      "chunk 28 score: 3\n",
      "Context lenght: 1261 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse:\n",
      "=========\n",
      "Les principaux thèmes de ce texte et les questions qui peuvent être posées sont les suivants :\n",
      "\n",
      "1. **L'inconscient numérique** :  \n",
      "   - L'idée d'un \"deuxième inconscient\" propre à l'ère numérique, distinct de l'inconscient psychanalytique ou idéologique, est proposée.  \n",
      "   - Question : L'IA peut-elle être considérée comme notre nouvel inconscient, étant donné sa capacité à analyser, stocker et traiter les données ?  \n",
      "\n",
      "2. **Le rêve prométhéen de l'IA** :  \n",
      "   - La quête de créer une machine intelligente \"au sens humain\", inspirée par un idéal prométhéen, est discutée.  \n",
      "   - Question : Où en est-on, 70 ans après l'émergence de ce rêve, dans la réalisation d'une IA véritablement intelligente ?  \n",
      "\n",
      "3. **La conscience et l'imitation de l'esprit humain** :  \n",
      "   - Débat sur la possibilité que l'IA puisse un jour remplacer la conscience humaine ou imiter les œuvres de l'esprit.  \n",
      "   - Questions :  \n",
      "     - L'intelligence peut-elle s'implémenter dans une machine non biologique ?  \n",
      "     - Comment se fait-il que la machine puisse imiter la pensée humaine ?  \n",
      "     - L'IA repose-t-elle sur une représentation biaisée ou incomplète de la conscience humaine ?  \n",
      "\n",
      "4. **Le test de Turing et la philosophie de l'esprit** :  \n",
      "   - Réflexions sur les critères pour évaluer l'intelligence ou la conscience des machines (comme le test de Turing).  \n",
      "   - Questions :  \n",
      "     - Qu'est-ce que comprendre ou être conscient pour une machine vs un humain ?  \n",
      "     - Peut-on vraiment affirmer qu'une machine \"ne comprend pas\" sans définir clairement ce qu'est la compréhension ?  \n",
      "\n",
      "5. **La créativité et la supériorité de l'IA** :  \n",
      "   - Exemple d'une IA surpassant un humain dans une tâche créative (écriture d'une nouvelle).  \n",
      "   - Question : L'IA peut-elle battre l'esprit humain dans des domaines considérés comme propres à l'humain, comme la créativité ?  \n",
      "\n",
      "6. **L'impact sociétal et philosophique** :  \n",
      "   - Interrogations sur les implications de l'IA pour le travail, la culture et la singularité de la pensée humaine.  \n",
      "   - Question : Les progrès de l'IA nous invitent-ils à reconsidérer la nature unique de l'intelligence humaine ?  \n",
      "\n",
      "Ces thèmes et questions illustrent une discussion complexe entre philosophie, psychanalyse, science et éthique, centrée sur les limites et les potentialités de l'intelligence artificielle."
     ]
    }
   ],
   "source": [
    "# rag_hyde=RAG_hybrid(model=\"mistralai/mistral-small-3.2-24b-instruct\")\n",
    "# rag_hyde=RAG_hybrid_HyDE(model=\"mistralai/mistral-large-2512\")\n",
    "rag_hyde=RAG_hybrid_HyDE(model=\"deepseek/deepseek-chat-v3-0324\")\n",
    "\n",
    "# 4. Ask a question\n",
    "question = \"Quels sont les principaux thèmes de ce texte et les questions qui peuvent être posées ?\"\n",
    "results = await rag_hyde.ask_llm(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "900faf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Document : *Les enjeux philosophiques et sociétaux de l’intelligence artificielle – Thèmes et questions clés***\n",
       "\n",
       "---\n",
       "\n",
       "### **Introduction**\n",
       "L’émergence de l’intelligence artificielle (IA), notamment depuis l’avènement de modèles comme ChatGPT en 2022, a bouleversé les perceptions traditionnelles de l’intelligence, de la créativité et de la conscience humaine. Ces avancées technologiques soulèvent des questions fondamentales en philosophie de l’esprit, en éthique, en sciences cognitives et en sociologie. Ce document explore les principaux thèmes abordés dans les débats contemporains sur l’IA, ainsi que les questions qu’ils suscitent, en s’appuyant sur des exemples concrets et des perspectives disciplinaires variées.\n",
       "\n",
       "---\n",
       "\n",
       "### **1. Les thèmes centraux**\n",
       "\n",
       "#### **A. La nature de l’intelligence et son implémentation artificielle**\n",
       "**Thème** : L’IA remet en cause l’idée selon laquelle l’intelligence serait une prérogative exclusive du cerveau biologique. Les performances des systèmes d’IA dans des tâches autrefois considérées comme \"humaines\" (rédaction, analyse, diagnostic, création artistique) interrogent la définition même de l’intelligence.\n",
       "\n",
       "- **Sous-thèmes** :\n",
       "  - **L’intelligence comme propriété émergente** : Peut-on réduire l’intelligence à un ensemble d’algorithmes et de données, ou implique-t-elle des dimensions irréductibles (conscience, intentionnalité, subjectivité) ?\n",
       "  - **Le dualisme et le matérialisme** : Les débats philosophiques classiques (Descartes, Searle, Chalmers) sont réactivés. L’IA peut-elle être \"consciente\" au même titre qu’un être humain, ou n’est-elle qu’une simulation ?\n",
       "  - **La mécanisation de la pensée** : Si une machine peut imiter des processus mentaux, cela signifie-t-il que la pensée humaine est elle-même mécanisable ? Cette question rejoint les travaux de Turing sur la \"machine universelle\" et les critiques ultérieures (comme l’argument de la \"chambre chinoise\" de Searle).\n",
       "\n",
       "**Exemple concret** : Le concours littéraire entre Hervé Le Tellier et ChatGPT (2025) illustre cette tension. Si une IA peut produire un texte jugé \"plus créatif\" qu’un écrivain humain, cela remet-il en cause la singularité de la créativité humaine, ou révèle-t-il simplement les limites de notre compréhension de cette dernière ?\n",
       "\n",
       "---\n",
       "\n",
       "#### **B. La créativité et l’originalité à l’ère de l’IA**\n",
       "**Thème** : La capacité des IA à générer des œuvres artistiques, littéraires ou musicales interroge la notion d’originalité et le rôle de l’auteur humain.\n",
       "\n",
       "- **Sous-thèmes** :\n",
       "  - **Créativité vs. imitation** : Les IA comme ChatGPT ou DALL·E créent à partir de données existantes. Leur \"créativité\" est-elle une recombinaison intelligente ou une véritable innovation ?\n",
       "  - **L’intentionnalité artistique** : Une œuvre générée par une IA a-t-elle un sens au-delà de son esthétique ? L’absence d’intention consciente chez la machine change-t-elle la valeur de l’œuvre ?\n",
       "  - **L’impact sur les métiers créatifs** : Les écrivains, musiciens ou designers sont-ils menacés par l’IA, ou celle-ci peut-elle devenir un outil collaboratif (comme l’a été la photographie pour la peinture) ?\n",
       "\n",
       "**Exemple concret** : Le débat autour de la nouvelle écrite par ChatGPT montre que la frontière entre création humaine et artificielle s’estompe. Certains y voient une opportunité (démocratisation de la création), d’autres une menace (dévalorisation du travail humain).\n",
       "\n",
       "---\n",
       "\n",
       "#### **C. L’IA et la philosophie de l’esprit**\n",
       "**Thème** : L’IA relance des questions anciennes sur la nature de la conscience, de la subjectivité et de l’esprit.\n",
       "\n",
       "- **Sous-thèmes** :\n",
       "  - **Le problème difficile de la conscience (Chalmers)** : Même si une IA peut simuler des comportements intelligents, peut-elle *ressentir* ou *expérimenter* ? La conscience est-elle une propriété émergente de systèmes complexes, ou est-elle irréductiblement biologique ?\n",
       "  - **L’IA comme miroir de l’esprit humain** : Les performances de l’IA reflètent-elles une compréhension profonde de l’intelligence humaine, ou révèlent-elles les limites de nos modèles théoriques (biais, incomplétude) ?\n",
       "  - **L’IA et l’identité humaine** : Si une machine peut imiter parfaitement un humain, qu’est-ce qui distingue encore l’homme de la machine ? Cette question rejoint les réflexions sur le transhumanisme et le post-humanisme.\n",
       "\n",
       "**Citation clé** :\n",
       "*\"Les miracles de l’IA nous inviteraient à explorer à nouveau frais l’irréductible singularité de notre propre pensée.\"* (Nathan Devert, France Culture)\n",
       "\n",
       "---\n",
       "\n",
       "#### **D. Les implications sociétales et éthiques**\n",
       "**Thème** : L’IA transforme le monde du travail, l’éducation, la santé et les rapports sociaux, soulevant des enjeux éthiques majeurs.\n",
       "\n",
       "- **Sous-thèmes** :\n",
       "  - **L’IA et l’emploi** : Automatisation des tâches intellectuelles (rédaction, analyse, diagnostic) vs. création de nouveaux métiers. Comment préparer les sociétés à ces mutations ?\n",
       "  - **Biais et éthique des algorithmes** : Les IA reproduisent-elles les biais présents dans leurs données d’entraînement ? Comment garantir leur équité et leur transparence ?\n",
       "  - **L’IA et la démocratie** : Les deepfakes, la désinformation et la manipulation algorithmique menacent-elles les processus démocratiques ?\n",
       "  - **L’IA et la santé** : Les diagnostics médicaux assistés par IA améliorent-ils les soins ou déshumanisent-ils la relation médecin-patient ?\n",
       "\n",
       "**Exemple concret** : Les débats autour de l’utilisation de l’IA en médecine (comme les outils de diagnostic de cancers) montrent à la fois son potentiel (précision, rapidité) et ses risques (dépendance technologique, perte de compétences humaines).\n",
       "\n",
       "---\n",
       "\n",
       "#### **E. L’IA comme outil de réflexion sur l’humain**\n",
       "**Thème** : Plutôt que de chercher à remplacer l’humain, l’IA peut être envisagée comme un moyen de mieux comprendre ce qui nous définit.\n",
       "\n",
       "- **Sous-thèmes** :\n",
       "  - **L’IA comme laboratoire philosophique** : En tentant de reproduire l’intelligence humaine, les chercheurs en IA révèlent les limites de nos théories sur l’esprit (ex. : le problème de la \"boîte noire\" des réseaux de neurones).\n",
       "  - **L’IA et la vulnérabilité humaine** : Les performances des IA peuvent susciter des réactions contradictoires : admiration (pour leur efficacité) et angoisse (face à la possible obsolescence de l’humain).\n",
       "  - **L’IA et la culture** : Les œuvres générées par IA interrogent la notion d’auteur, de propriété intellectuelle et de patrimoine culturel.\n",
       "\n",
       "**Citation clé** :\n",
       "*\"L’intelligence artificielle, notre deuxième conscience.\"* (Nathan Devert)\n",
       "\n",
       "---\n",
       "\n",
       "### **2. Questions ouvertes et pistes de réflexion**\n",
       "\n",
       "Les thèmes abordés ci-dessus soulèvent des questions fondamentales, encore largement débattues. En voici une sélection non exhaustive :\n",
       "\n",
       "#### **Sur la nature de l’intelligence et de la conscience**\n",
       "1. Une IA peut-elle être *vraiment* intelligente, ou ne fait-elle que simuler l’intelligence ?\n",
       "2. La conscience est-elle une propriété émergente de systèmes complexes (biologiques ou artificiels), ou est-elle irréductiblement liée à la matière vivante ?\n",
       "3. Si une IA passait le test de Turing, cela signifierait-il qu’elle est consciente, ou simplement qu’elle imite parfaitement un humain ?\n",
       "\n",
       "#### **Sur la créativité et l’art**\n",
       "4. Une œuvre générée par une IA peut-elle être considérée comme \"artistique\" au même titre qu’une œuvre humaine ?\n",
       "5. L’absence d’intention consciente chez une IA change-t-elle la valeur esthétique ou émotionnelle d’une œuvre ?\n",
       "6. Les artistes humains doivent-ils craindre l’IA, ou celle-ci peut-elle devenir un partenaire créatif ?\n",
       "\n",
       "#### **Sur les implications sociétales**\n",
       "7. Comment les sociétés peuvent-elles se préparer aux transformations du marché du travail induites par l’IA ?\n",
       "8. Quels garde-fous éthiques et juridiques mettre en place pour encadrer le développement de l’IA (ex. : transparence des algorithmes, responsabilité en cas d’erreur) ?\n",
       "9. L’IA peut-elle aggraver les inégalités sociales, ou au contraire contribuer à les réduire ?\n",
       "\n",
       "#### **Sur la philosophie de l’esprit**\n",
       "10. Les performances de l’IA remettent-elles en cause les théories dualistes (esprit/corps) ou matérialistes de la conscience ?\n",
       "11. Si une IA peut imiter parfaitement un humain, qu’est-ce qui distingue encore l’homme de la machine ?\n",
       "12. L’IA peut-elle nous aider à mieux comprendre le fonctionnement de l’esprit humain, ou ne fait-elle que refléter nos propres limites théoriques ?\n",
       "\n",
       "#### **Sur l’avenir de l’humanité**\n",
       "13. L’IA représente-t-elle une menace existentielle pour l’humanité (scénarios dystopiques), ou une opportunité de dépassement (transhumanisme) ?\n",
       "14. Comment concilier les promesses de l’IA (amélioration des conditions de vie, avancées scientifiques) avec ses risques (perte d’autonomie humaine, surveillance de masse) ?\n",
       "15. Faut-il réguler le développement de l’IA au niveau international, et si oui, comment ?\n",
       "\n",
       "---\n",
       "\n",
       "### **3. Perspectives disciplinaires**\n",
       "Les questions soulevées par l’IA sont abordées sous différents angles par les disciplines suivantes :\n",
       "\n",
       "| **Discipline**       | **Approche**                                                                 | **Auteurs/Théories clés**                          |\n",
       "|----------------------|-----------------------------------------------------------------------------|---------------------------------------------------|\n",
       "| **Philosophie**      | Nature de l’esprit, conscience, éthique, dualisme/matérialisme.             | Descartes, Searle (argument de la chambre chinoise), Chalmers (problème difficile), Turing (test de Turing). |\n",
       "| **Sciences cognitives** | Modélisation de l’intelligence, apprentissage, mémoire.                   | Newell & Simon (théorie des systèmes symboliques), connexionnisme (réseaux de neurones). |\n",
       "| **Informatique**     | Développement d’algorithmes, apprentissage automatique, éthique des données. | Deep learning (LeCun, Hinton, Bengio), biais algorithmiques (Buolamwini, Gebru). |\n",
       "| **Sociologie**       | Impact sur le travail, les inégalités, la culture.                          | Zuboff (*Le Capitalisme de surveillance*), Brynjolfsson & McAfee (*The Second Machine Age*). |\n",
       "| **Droit**           | Régulation, propriété intellectuelle, responsabilité.                       | RGPD (protection des données), débats sur les droits des IA. |\n",
       "| **Éthique**          | Biais, transparence, équité, autonomie.                                     | Principes d’Asilomar, éthique de l’IA (Bostrom, Floridi). |\n",
       "\n",
       "---\n",
       "\n",
       "### **4. Conclusion**\n",
       "L’intelligence artificielle n’est pas seulement une révolution technologique : elle est un miroir tendu à l’humanité, nous invitant à repenser les fondements mêmes de notre intelligence, de notre créativité et de notre conscience. Les débats qu’elle suscite – entre fascination et inquiétude – reflètent les tensions entre progrès et préservation de ce qui fait notre humanité.\n",
       "\n",
       "Plutôt que de chercher à trancher définitivement ces questions, il est essentiel d’adopter une approche pluridisciplinaire, associant scientifiques, philosophes, éthiciens et citoyens, pour guider le développement de l’IA vers des usages bénéfiques et responsables. Comme le soulignait Daniel Andler dans le débat cité, l’enjeu n’est pas tant de savoir si l’IA peut *remplacer* l’humain, mais de comprendre ce que ces technologies nous révèlent sur nous-mêmes.\n",
       "\n",
       "---\n",
       "\n",
       "### **Ressources complémentaires**\n",
       "- **Ouvrages** :\n",
       "  - Andler, D. (2023). *Intelligence artificielle, intelligence humaine : la double énigme*. Gallimard.\n",
       "  - Devillers, L. (2025). *L’IA, ange ou démon*. Éditions du Serge.\n",
       "  - Bostrom, N. (2014). *Superintelligence : Paths, Dangers, Strategies*. Oxford University Press.\n",
       "  - Searle, J. (1980). \"Minds, Brains, and Programs\". *Behavioral and Brain Sciences*.\n",
       "\n",
       "- **Émissions et podcasts** :\n",
       "  - *France Culture – \"Sans préjuger\"* (débat avec Daniel Andler, Laurence Devillers et Valentin Husson).\n",
       "  - *Lex Fridman Podcast* (interviews avec des chercheurs en IA comme Yann LeCun ou Stuart Russell).\n",
       "\n",
       "- **Articles scientifiques** :\n",
       "  - Turing, A. (1950). \"Computing Machinery and Intelligence\". *Mind*.\n",
       "  - Chalmers, D. (1995). \"Facing Up to the Problem of Consciousness\". *Journal of Consciousness Studies*."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(rag_hybrid.hypothetical_document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8fbae41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 22)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph-RAG:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'creation_tokens_input': 88941,\n",
       " 'creation_tokens_output': 16238,\n",
       " 'creation_cost_total': 0.05,\n",
       " 'qa_tokens_input': 17606,\n",
       " 'qa_tokens_output': 938,\n",
       " 'qa_cost_total': 0.0046}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid-RAG:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'reranker_tokens_input': 5468,\n",
       " 'reranker_tokens_output': 150,\n",
       " 'generation_tokens_input': 871,\n",
       " 'generation_tokens_output': 348,\n",
       " 'total_tokens_input': 6339,\n",
       " 'total_tokens_output': 498,\n",
       " 'cost_total': 0.0029}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid-HyDE-RAG:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hyde_doc_generation_tokens_input': 1785,\n",
       " 'hyde_doc_generation_tokens_output': 1127,\n",
       " 'reranker_tokens_input': 10425,\n",
       " 'reranker_tokens_output': 280,\n",
       " 'generation_tokens_input': 2280,\n",
       " 'generation_tokens_output': 619,\n",
       " 'total_tokens_input': 14490,\n",
       " 'total_tokens_output': 2026,\n",
       " 'cost_total': 0.0063}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### Couts Graph VS vectoriel\n",
    "import pandas\n",
    "\n",
    "df_activity=pandas.read_csv(\"openrouter_activity.csv\")\n",
    "\n",
    "display(df_activity.shape)\n",
    "\n",
    "#===== graph rag\n",
    "graph_rag_activity={}\n",
    "df_activity_graphrag_creation=df_activity[df_activity[\"user\"]==\"audio-graphrag-creation\"]\n",
    "graph_rag_activity[\"creation_tokens_input\"]=df_activity_graphrag_creation[\"tokens_prompt\"].sum().item()\n",
    "graph_rag_activity[\"creation_tokens_output\"]=(df_activity_graphrag_creation[\"tokens_reasoning\"].sum()+df_activity_graphrag_creation[\"tokens_completion\"].sum()).item()\n",
    "graph_rag_activity[\"creation_cost_total\"]=round(df_activity_graphrag_creation[\"cost_total\"].sum().item(),2)\n",
    "\n",
    "df_activity_graphrag_qa=df_activity[df_activity[\"user\"]==\"audio-graphrag-qa\"]\n",
    "graph_rag_activity[\"qa_tokens_input\"]=df_activity_graphrag_qa[\"tokens_prompt\"].sum().item()\n",
    "graph_rag_activity[\"qa_tokens_output\"]=(df_activity_graphrag_qa[\"tokens_reasoning\"].sum()+df_activity_graphrag_qa[\"tokens_completion\"].sum()).item()\n",
    "graph_rag_activity[\"qa_cost_total\"]=round(df_activity_graphrag_qa[\"cost_total\"].sum().item(),4)\n",
    "\n",
    "print(\"Graph-RAG:\")\n",
    "display(graph_rag_activity)\n",
    "\n",
    "\n",
    "# ===== hybrid RAG \n",
    "hybrid_rag_activity={}\n",
    "df_activity_hybrid_global=df_activity[df_activity[\"user\"].str.contains(\"audio-hybrid\")]\n",
    "df_activity_hybrid_reranker=df_activity_hybrid_global[df_activity_hybrid_global[\"user\"].str.contains(\"reranker\")]\n",
    "df_activity_hybrid_generation=df_activity_hybrid_global[df_activity_hybrid_global[\"user\"].str.contains(\"generation\")]\n",
    "\n",
    "hybrid_rag_activity[\"reranker_tokens_input\"]=df_activity_hybrid_reranker[\"tokens_prompt\"].sum().item()\n",
    "hybrid_rag_activity[\"reranker_tokens_output\"]=(df_activity_hybrid_reranker[\"tokens_reasoning\"].sum()+df_activity_hybrid_reranker[\"tokens_completion\"].sum()).item()\n",
    "hybrid_rag_activity[\"generation_tokens_input\"]=df_activity_hybrid_generation[\"tokens_prompt\"].sum().item()\n",
    "hybrid_rag_activity[\"generation_tokens_output\"]=(df_activity_hybrid_generation[\"tokens_reasoning\"].sum()+df_activity_hybrid_generation[\"tokens_completion\"].sum()).item()\n",
    "hybrid_rag_activity[\"total_tokens_input\"]=hybrid_rag_activity[\"reranker_tokens_input\"]+hybrid_rag_activity[\"generation_tokens_input\"]\n",
    "hybrid_rag_activity[\"total_tokens_output\"]=hybrid_rag_activity[\"reranker_tokens_output\"]+hybrid_rag_activity[\"generation_tokens_output\"]\n",
    "\n",
    "hybrid_rag_activity[\"cost_total\"]=round(df_activity_hybrid_global[\"cost_total\"].sum().item(),4)\n",
    "\n",
    "\n",
    "print(\"Hybrid-RAG:\")\n",
    "display(hybrid_rag_activity)\n",
    "\n",
    "\n",
    "#======= hybrid RAG with HyDE\n",
    "hybrid_hyde_rag_activity={}\n",
    "df_activity_hyde_global=df_activity[df_activity[\"user\"].str.contains(\"audio-hyde\")]\n",
    "df_activity_hyde_query_document=df_activity_hyde_global[df_activity_hyde_global[\"user\"].str.contains(\"query-document\")]\n",
    "df_activity_hyde_reranker=df_activity_hyde_global[df_activity_hyde_global[\"user\"].str.contains(\"reranker\")]\n",
    "df_activity_hyde_generation=df_activity_hyde_global[df_activity_hyde_global[\"user\"].str.contains(\"generation\")]\n",
    "\n",
    "\n",
    "hybrid_hyde_rag_activity[\"hyde_doc_generation_tokens_input\"]=df_activity_hyde_query_document[\"tokens_prompt\"].sum().item()\n",
    "hybrid_hyde_rag_activity[\"hyde_doc_generation_tokens_output\"]=df_activity_hyde_query_document[\"tokens_reasoning\"].sum().item()+df_activity_hyde_query_document[\"tokens_completion\"].sum().item()\n",
    "\n",
    "hybrid_hyde_rag_activity[\"reranker_tokens_input\"]=df_activity_hyde_reranker[\"tokens_prompt\"].sum().item()\n",
    "hybrid_hyde_rag_activity[\"reranker_tokens_output\"]=(df_activity_hyde_reranker[\"tokens_reasoning\"].sum()+df_activity_hyde_reranker[\"tokens_completion\"].sum()).item()\n",
    "\n",
    "hybrid_hyde_rag_activity[\"generation_tokens_input\"]=df_activity_hyde_generation[\"tokens_prompt\"].sum().item()\n",
    "hybrid_hyde_rag_activity[\"generation_tokens_output\"]=(df_activity_hyde_generation[\"tokens_reasoning\"].sum()+df_activity_hyde_generation[\"tokens_completion\"].sum()).item()\n",
    "\n",
    "hybrid_hyde_rag_activity[\"total_tokens_input\"]=hybrid_hyde_rag_activity[\"hyde_doc_generation_tokens_input\"]+ hybrid_hyde_rag_activity[\"reranker_tokens_input\"]+hybrid_hyde_rag_activity[\"generation_tokens_input\"]\n",
    "hybrid_hyde_rag_activity[\"total_tokens_output\"]=hybrid_hyde_rag_activity[\"hyde_doc_generation_tokens_output\"]+ hybrid_hyde_rag_activity[\"reranker_tokens_output\"]+hybrid_hyde_rag_activity[\"generation_tokens_output\"]\n",
    "\n",
    "hybrid_hyde_rag_activity[\"cost_total\"]=round(df_activity_hyde_global[\"cost_total\"].sum().item(),4)\n",
    "\n",
    "\n",
    "print(\"Hybrid-HyDE-RAG:\")\n",
    "display(hybrid_hyde_rag_activity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "75069eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "méthodes = [\"Graph-RAG\", 'Hybrid-RAG', 'Hybrid-HyDE-RAG']\n",
    "coûts = [graph_rag_activity[\"qa_cost_total\"], hybrid_rag_activity[\"cost_total\"], hybrid_hyde_rag_activity[\"cost_total\"]]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "bars = ax.bar(méthodes, coûts, color=['#2E86AB', '#A23B72', '#F18F01'])\n",
    "ax.set_ylabel('Coût total ($)', fontsize=12)\n",
    "ax.set_title('Comparaison des coûts totaux par méthode (QA)', fontsize=14, pad=20)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar, coût in zip(bars, coûts):\n",
    "    height = bar.get_height()\n",
    "    ax.text(bar.get_x() + bar.get_width()/2., height + 0.0000,\n",
    "            f'${coût:.4f}', ha='center', va='bottom', fontsize=11)\n",
    "\n",
    "# plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14268d0",
   "metadata": {},
   "source": [
    "Commentaires:\n",
    "* le même llm a été utilisé sur toutes les méthodes, sauf le reranker (mistral small 24b)\n",
    "* Au démarrage le graph rag est le + cher à cause de la création du graphe\n",
    "* Hors création du graph, la méthode hyde semble la plus chère, mais essentiellement à cause de la longueur de la réponse:\n",
    "    * hyde: 2000 tokens \n",
    "    * graph: 1000 tokens \n",
    "    * hybrid simple: 500 tokens\n",
    "* Classement fait avec gemini 3 pro:\n",
    "\n",
    "| Réponse | Score | Verdict |\n",
    "| :--- | :---: | :--- |\n",
    "| **Graph RAG** | **8.5/10** | Très bonne, excellente structure, mais peut-être moins précise sur le concept clé du texte. |\n",
    "| **Hybrid simple** | **6.0/10** | Trop synthétique, structure confuse entre thèmes et questions. |\n",
    "| **Hybrid HyDE** | **9.5/10** | **Gagnante.** Complète, précise, structure logique liant thèmes et questions. |\n",
    "\n",
    "\n",
    "* En utilisant mistral 3 large (sur le QA) le Graph RAG prend la place de HyDE, et hybrid simple gagne 1 point\n",
    "* Avec HyDE on peut gagner marginalement avec un + petit LLM (ministral 14b ou gemma 12b), voir un reranker cross encoder, mais avec risque de scores moins pertinents (surtout avec cross encoder)\n",
    "* L'input tokens sur le graph RAG lors des QA me semble trop élevé:\n",
    "> Pour une question simple et directe `Qui sont les intervenants dans ce texte ?`, l'input token est de 21k (vs 17k pour la question de référence)\n",
    ">> Il faudra regarder le détail de la constitution du contexte par la librairie graph\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4f2574",
   "metadata": {},
   "source": [
    "==============================\n",
    "\n",
    "### Evaluation des réponses\n",
    "#### <u>Le cadre général:</u>\n",
    "**1. Construire les réponses de référence:**\n",
    "* Utiliser la question cadre \"Quels sont les principaux thèmes de ce texte ?\" \n",
    "* Charger le transcript du podcast et produire la réponse avec les modèles suivant:\n",
    "    * Dans le chat openrouter ou par API:\n",
    "        * openai/gpt-5.2\n",
    "        * google/gemini-3-pro-preview\n",
    "        * anthropic/claude-sonnet-4.5\n",
    "    * Dans NotebookLM (solution spécialisée dans l'analyse des documents)\n",
    "    \n",
    "**Important**: relire et comparer les réponses avec votre compréhension du podcast, corriger et valider\n",
    "\n",
    "**2. Utiliser les réponses de référence pour évaluer les RAGs:**\n",
    "\n",
    "Pour la question cadre ci dessus, le graphrag est plus apte que le vectoriel\n",
    "\n",
    "Il existe 2 paramètres techniques principaux qui influencent nettement la qualité des réponses:\n",
    "* Le modèle d'embedding: \n",
    "    * Utilisé lors de la création du graphe dans la structuration des noeuds et leur connexion (par rapprochement cosine sim)\n",
    "    * Utilisé lors de la lecture du graphe pour répondre à une question, qui mets en relation avec la question avec les noeuds les plus pertinent (cosine sim) pour sélectionner un/des point(s) de démarrage pour l'exploration du graphe\n",
    "* Le LLM:\n",
    "    * Utilisé lors de la création du graphe pour la reconnaissance des entités, leur définition a rôles, leurs catégories, les relations entre les entités, la normalisation, déduplication et unification des entités et des catégories ...\n",
    "    * Utilisé lors de la génération de la réponse, en recevant en entrée les pertinentes parties du graphe comme contexte\n",
    "\n",
    "#### Un tableau de combinaisons pour l'évaluation\n",
    "\n",
    "Exemple de grille systématique pour tester les combinaisons de modèles d'embedding et de LLM :\n",
    "\n",
    "## **Paramètres de Test**\n",
    "\n",
    "### **Modèles d'Embedding (Colonnes)**\n",
    "1. **Embedding bon marché**:\n",
    "* gemma embeddign 300m, ...\n",
    "2. **Embeddings premium**:\n",
    "* gemini embedding (via openrouter)\n",
    "* openai text-embedding-3-large\n",
    "\n",
    "\n",
    "### **Modèles LLM (Lignes)**\n",
    "**Pour la création de graphe:**\n",
    "#### Modèles `performants` et bon marché, éligible pour création de graphe:\n",
    "* deepseek/deepseek-chat-v3-0324: $0.20/M input tokens | $0.88/M output tokens\n",
    "* deepseek/deepseek-v3.1-terminus: $0.21/M input tokens | $0.79/M output tokens\n",
    "* prime-intellect/intellect-3: $0.20/M input tokens | $1.10/M output tokens\n",
    "* openai/gpt-5-mini: $0,25/M input tokens | $2/M output tokens\n",
    "* mistralai/mistral-large-2512: $0.50/M input tokens | $1.50/M output tokens\n",
    "* mistralai/mistral-medium-3.1; $0.40/M input tokens | $2/M output tokens\n",
    "\n",
    "#### Modèles `frontière`, meilleure qualité attendue, mais prix élevé pour modèles US:\n",
    "<div class=\"alert\" style=\"color: red\">Attention au prix de l'output variable</div>\n",
    "\n",
    "* google/gemini-2.5-pro: Starting at $1.25/M input tokens | Starting at $10/M output tokens\n",
    "* openai/gpt-5.1: $1.25/M input tokens | $10/M output tokens\n",
    "* deepseek/deepseek-v3.2: $0.28/M input tokens | $0.42/M output tokens\n",
    "* moonshotai/kimi-k2-thinking: $0.45/M input tokens | $2.35/M output tokens\n",
    "* z-ai/glm-4.6; $0.39/M input tokens | $1.90/M output tokens\n",
    "\n",
    "**Pour la génération de réponse:**\n",
    "En plus des modèles `tiers 2` ci dessus, envisager les modèles suivants, assez performants pour des questions de moindre complexité, et particulièrement peu chers;\n",
    "\n",
    "* mistralai/mistral-small-3.2-24b-instruct: $0.06/M input tokens | $0.18/M output tokens\n",
    "* meta-llama/llama-4-maverick: $0.15/M input tokens | $0.60/M output tokens\n",
    "* z-ai/glm-4.5-air: $0.104/M input tokens | $0.68/M output tokens\n",
    "* google/gemma-3-27b-it: $0.04/M input tokens | $0.15/M output tokens\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## **Tableau de combinaisons (Grid Search)**\n",
    "\n",
    "| Combinaison | Embedding | LLM (Création) | LLM (Génération) | Coût Relatif | Gestion de la complexité |\n",
    "|-------------|-----------|----------------|------------------|--------------|------------|\n",
    "| **C1 - Baseline Économique** | gemma emb | google/gemma-3-27b-it | google/gemma-3-27b-it | Très faible | Simple |\n",
    "| **C2 - Hybride Léger** | gemma emb | deepseek-v3.1-terminus | mistral small | Faible | moyenne |\n",
    "| **C3 - Optimal Qualité** | gemma emb | deepseek/deepseek-v3.2 | deepseek/deepseek-v3.2 | Moyen | Elevée |\n",
    "| **C4 - Maximum Performance** | gemini ou openai large | openai/gpt-5.1 | openai/gpt-5.1 | Très élevé | Elevée|\n",
    "\n",
    "\n",
    "## **Métriques d'Évaluation par combinaison**\n",
    "\n",
    "### **Pour chaque combinaison, mesurer :**\n",
    "1. **Qualité RAG**\n",
    "   - Précision et couverture de la réponse VS référence\n",
    "   - RAGAS (Faithfulness, Answer Relevancy)\n",
    "   - Hallucinations\n",
    "\n",
    "2. **Performance Technique**\n",
    "   - Temps création graphe / génération réponses\n",
    "   - Coût pour création de graphe\n",
    "   - Coût par requête\n",
    "\n",
    "3. **Qualité Graphe**\n",
    "   - Nb de catégories formées\n",
    "   - Nb de noeuds formés\n",
    "   - Nombre de connexions\n",
    "\n",
    "\n",
    "\n",
    "## **Matrice de Décision**\n",
    "\n",
    "| Critère | Poids | C1 | C2 | C3 | C4 |\n",
    "|---------|-------|----|----|----|----|\n",
    "| **Qualité Réponse** | 70% | ⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ |\n",
    "| **Coût création graphe** | 10% | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ | ⭐ |\n",
    "| **Coût génération réponse** | 15% | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐ |\n",
    "| **Temps** | 5% | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐ |\n",
    "| **Score Total** | 100% | **58** | **68** | **72** | **77** |\n",
    "\n",
    "## **Recommandations**\n",
    "\n",
    "1. **Démarrer avec C3** (Optimal Qualité)\n",
    "* Si objectif qualité atteint (proche de C4 - Maximum Performance), tester C3 et mesurer la dégradation\n",
    "* Si objectif qualité non atteint passer à C4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2705bfad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
