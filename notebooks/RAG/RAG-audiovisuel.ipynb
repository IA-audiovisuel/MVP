{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b419c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠦ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling 0800cbac9c20: 100% ▕██████████████████▏ 621 MB                         \u001b[K\n",
      "pulling 1adbfec9dcf0: 100% ▕██████████████████▏ 8.4 KB                         \u001b[K\n",
      "pulling 45dc10444b87: 100% ▕██████████████████▏   34 B                         \u001b[K\n",
      "pulling 3901c6a1d7c2: 100% ▕██████████████████▏  416 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# créer un nouvel env conda à partir du terminal\n",
    "# conda create --name pathrag python=3.10\n",
    "# installer ollama: https://www.ollama.com/download\n",
    "\n",
    "# installer les dépendences\n",
    "#%pip install -r requirements.txt\n",
    "# intsaller le modème d'OllamaEmbeddings\n",
    "!ollama pull embeddinggemma\n",
    "# créer une clé api sur openrouter pour utiliser des llm gratuitement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0299e812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chougar/miniconda3/envs/pathrag/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain.schema.document import Document\n",
    "from pathrag_retriever import create_graphdb, load_existing_graphdb, load_knowledgeGraph_vis\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b573138d",
   "metadata": {},
   "source": [
    "#### Base vectorielle\n",
    "Création de la base vect. avec le PP Mahakam (20 premières pages, ligne 45 `docs[:20]`)\n",
    "\n",
    "Relancer la cellule à chaque ouverture pour utiliser le rag vectoriel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "514d8aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 documents from audio-text.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n",
      "INFO:httpx:HTTP Request: POST http://127.0.0.1:11434/api/embed \"HTTP/1.1 200 OK\"\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event CollectionGetEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb de chuncks: 30\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.retrievers import TFIDFRetriever\n",
    "from langchain_unstructured import UnstructuredLoader\n",
    "\n",
    "#========= choix du modèle d'embedding\n",
    "\"\"\"\n",
    "    Le modèle choisi impacte la qualité du retriever, mais aussi le temps de traitement\n",
    "    Si le déploiement est prévu sur une VM limitée, un modèle plus petit est nécessaire\n",
    "    Explorer les comparatifs: https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "\"\"\"\n",
    "# Utiliser OllamaEmbeddings avec le modèle local \"embeddinggemma\"\n",
    "embeddings = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "\n",
    "\n",
    "\n",
    "# chargement et fragmentation du doc\n",
    "## Nom du doc à traiter\n",
    "filename=\"audio-text.txt\"\n",
    "\n",
    "## Nom pour la base vectorielle\n",
    "doc_name_hybrid=\"L-IA-notre-deuxieme-conscience_sample\" # nom de doc significatif\n",
    "\n",
    "\n",
    "# loader = UnstructuredFileLoader(filename)\n",
    "loader = UnstructuredLoader(filename)\n",
    "\n",
    "txt_doc = loader.load()\n",
    "print(f\"Loaded {len(txt_doc)} documents from {filename}\")\n",
    "\n",
    "\n",
    "#======== choix des paramètres de fragmentation\n",
    "\"\"\"\n",
    "    la taille du chunck_size est très important dans l'accès à une info précise\n",
    "    une plus petite taille permet de cibler de courts passages contenant l'info nécessaire à des réponses précises:\n",
    "        * lieu du projet\n",
    "        * dates du projet\n",
    "        * budget ...    \n",
    "    l'envoi de passages plus courts au llm évite une dispertion de son attention\n",
    "\"\"\"\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "docs = text_splitter.split_documents(txt_doc)\n",
    "\n",
    "# Filter out complex metadata (e.g., lists, dicts)\n",
    "docs = [Document(doc.page_content) for doc in docs]\n",
    "\n",
    "\n",
    "# Conversion des docs en embeddings \n",
    "chroma_db = Chroma.from_documents(\n",
    "    docs,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=f'./storage/vector_scores/{doc_name_hybrid.replace(\" \",\"_\")}',\n",
    "    collection_name=doc_name_hybrid.replace(\" \",\"_\")\n",
    ")\n",
    "\n",
    "retriever=chroma_db.as_retriever()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ...existing code...\n",
    "all_docs = chroma_db.get()\n",
    "print(\"Nb de chuncks:\", len(all_docs['documents']))  # This will print the total number of docs stored\n",
    "# ...existing code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6d50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Nathan Devers]: France Culture. Sans préjugés. Natacha Devers. Comment expliquer les progrès phénoménaux que semble avoir accomplis l'intelligence artificielle au cours de ces dernières années ? Depuis l'apparition de ChatGPT en novembre 2022, rapidement suivi par d'autres agents conversationnels. Cette révolution technologique aux multiples aspects, paraît désormais capable d'exécuter de nombreuses tâches intellectuelles sur lesquelles l'esprit humain pensait jusqu'alors exercer un monopole. Écrire des articles, synthétiser des documents, traiter des données dans n'importe quel domaine, diagnostiquer une maladie, rédiger une dissertation, ou pourquoi pas un scénario de film. Non contente de révolutionner le monde du travail, ses prouesses stupéfiantes de la technique soulèvent une interrogation majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans \n",
      "=============\n",
      "majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans n'importe quelle machine, voir, comme s'inquiètent ou exultent certains, que l'IA sera un jour en mesure de remplacer notre conscience. À moins qu'il ne faille poser cette question à l'envers. Comment se fait-il que la machine puisse imiter les œuvres de notre esprit ? Comment est-il possible en d'autres termes que notre vie mentale se révèle comme mécanisable au même titre que nos facultés manuelles. L'intelligence artificielle ne doit-elle pas sa capacité d'imitation au fait qu'elle a été théorisée, inventée, développée d'après une certaine représentation, peut-être incomplète ou biaisée des ressorts de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième \n",
      "=============\n",
      "de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième conscience. À l'occasion de la fête de la science, j'aurai le plaisir d'en débattre sans préjugé aux côtés du mathématicien et philosophe Daniel Andler, de la professeur en intelligence artificielle et chercheuse Laurence Devillers et du philosophe Valentin Husson. [Narrateur Radio]: France Culture, sans préjugé. [Nathan Devers]: Nathan Devert. Bonjour Laurence Devillers. [Laurence Devillers]: Bonjour. [Nathan Devers]: Vous êtes professeur en intelligence artificielle à Sorbonne Université, chercheuse au CNRS, auteur de \"L'IA Ange ou Démon\" paru en 2025 aux éditions du Seuil et présidente de la Fondation Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences \n",
      "=============\n",
      "Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences morales et politiques et auteur de \"Intelligence artificielle, intelligence humaine, la double énigme\" aux éditions Gallimard et bonjour Valentin Husson. Vous êtes philosophe et auteur de \"Folle, Ressentimentale, petite philosophie des trolls\" chez philosophie Magazine éditeur qui vient de paraître. Alors pour commencer cette cette discussion sur l'intelligence artificielle, je voulais vous soumettre une histoire qui a eu lieu récemment en mars 2025. Le nouvel Obs a décidé d'organiser un concours littéraire entre deux auteurs entre guillemets. Alors le premier était Hervé Le Tellier prix Goncourt 2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre \n",
      "=============\n",
      "2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre guillemets de rédiger une nouvelle et puis avec la première phrase qui était indiquée c'était quelqu'un qui découvrait un cadavre et la dernière phrase de la nouvelle aussi. Hervé Le Tellier a rendu sa copie, ChatGPT aussi et de l'aveu même de Hervé Le Tellier il a dit franchement, je suis absolument bluffé par la créativité littéraire entre guillemets de ChatGPT, peut-être même que ChatGPT m'a battu que la nouvelle qui a été rendue par l'intelligence artificielle était plus drôle, plus originale, plus vive que celle que j'ai écrite et peut-être donc que ça inaugure un monde où les écrivains seront moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus \n",
      "=============\n",
      "moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus propre la créativité ? [Daniel Andler]: je ne le pense pas mais je pense que c'est pas original de pas le penser. \n",
      "=============\n",
      "[Nathan Devers]: France Culture. Sans préjugés. Natacha Devers. Comment expliquer les progrès phénoménaux que semble avoir accomplis l'intelligence artificielle au cours de ces dernières années ? Depuis l'apparition de ChatGPT en novembre 2022, rapidement suivi par d'autres agents conversationnels. Cette révolution technologique aux multiples aspects, paraît désormais capable d'exécuter de nombreuses tâches intellectuelles sur lesquelles l'esprit humain pensait jusqu'alors exercer un monopole. Écrire des articles, synthétiser des documents, traiter des données dans n'importe quel domaine, diagnostiquer une maladie, rédiger une dissertation, ou pourquoi pas un scénario de film. Non contente de révolutionner le monde du travail, ses prouesses stupéfiantes de la technique soulèvent une interrogation majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans \n",
      "=============\n",
      "majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans n'importe quelle machine, voir, comme s'inquiètent ou exultent certains, que l'IA sera un jour en mesure de remplacer notre conscience. À moins qu'il ne faille poser cette question à l'envers. Comment se fait-il que la machine puisse imiter les œuvres de notre esprit ? Comment est-il possible en d'autres termes que notre vie mentale se révèle comme mécanisable au même titre que nos facultés manuelles. L'intelligence artificielle ne doit-elle pas sa capacité d'imitation au fait qu'elle a été théorisée, inventée, développée d'après une certaine représentation, peut-être incomplète ou biaisée des ressorts de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième \n",
      "=============\n",
      "de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième conscience. À l'occasion de la fête de la science, j'aurai le plaisir d'en débattre sans préjugé aux côtés du mathématicien et philosophe Daniel Andler, de la professeur en intelligence artificielle et chercheuse Laurence Devillers et du philosophe Valentin Husson. [Narrateur Radio]: France Culture, sans préjugé. [Nathan Devers]: Nathan Devert. Bonjour Laurence Devillers. [Laurence Devillers]: Bonjour. [Nathan Devers]: Vous êtes professeur en intelligence artificielle à Sorbonne Université, chercheuse au CNRS, auteur de \"L'IA Ange ou Démon\" paru en 2025 aux éditions du Seuil et présidente de la Fondation Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences \n",
      "=============\n",
      "Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences morales et politiques et auteur de \"Intelligence artificielle, intelligence humaine, la double énigme\" aux éditions Gallimard et bonjour Valentin Husson. Vous êtes philosophe et auteur de \"Folle, Ressentimentale, petite philosophie des trolls\" chez philosophie Magazine éditeur qui vient de paraître. Alors pour commencer cette cette discussion sur l'intelligence artificielle, je voulais vous soumettre une histoire qui a eu lieu récemment en mars 2025. Le nouvel Obs a décidé d'organiser un concours littéraire entre deux auteurs entre guillemets. Alors le premier était Hervé Le Tellier prix Goncourt 2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre \n",
      "=============\n",
      "2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre guillemets de rédiger une nouvelle et puis avec la première phrase qui était indiquée c'était quelqu'un qui découvrait un cadavre et la dernière phrase de la nouvelle aussi. Hervé Le Tellier a rendu sa copie, ChatGPT aussi et de l'aveu même de Hervé Le Tellier il a dit franchement, je suis absolument bluffé par la créativité littéraire entre guillemets de ChatGPT, peut-être même que ChatGPT m'a battu que la nouvelle qui a été rendue par l'intelligence artificielle était plus drôle, plus originale, plus vive que celle que j'ai écrite et peut-être donc que ça inaugure un monde où les écrivains seront moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus \n",
      "=============\n",
      "moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus propre la créativité ? [Daniel Andler]: je ne le pense pas mais je pense que c'est pas original de pas le penser. \n",
      "=============\n",
      "[Nathan Devers]: France Culture. Sans préjugés. Natacha Devers. Comment expliquer les progrès phénoménaux que semble avoir accomplis l'intelligence artificielle au cours de ces dernières années ? Depuis l'apparition de ChatGPT en novembre 2022, rapidement suivi par d'autres agents conversationnels. Cette révolution technologique aux multiples aspects, paraît désormais capable d'exécuter de nombreuses tâches intellectuelles sur lesquelles l'esprit humain pensait jusqu'alors exercer un monopole. Écrire des articles, synthétiser des documents, traiter des données dans n'importe quel domaine, diagnostiquer une maladie, rédiger une dissertation, ou pourquoi pas un scénario de film. Non contente de révolutionner le monde du travail, ses prouesses stupéfiantes de la technique soulèvent une interrogation majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans \n",
      "=============\n",
      "majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans n'importe quelle machine, voir, comme s'inquiètent ou exultent certains, que l'IA sera un jour en mesure de remplacer notre conscience. À moins qu'il ne faille poser cette question à l'envers. Comment se fait-il que la machine puisse imiter les œuvres de notre esprit ? Comment est-il possible en d'autres termes que notre vie mentale se révèle comme mécanisable au même titre que nos facultés manuelles. L'intelligence artificielle ne doit-elle pas sa capacité d'imitation au fait qu'elle a été théorisée, inventée, développée d'après une certaine représentation, peut-être incomplète ou biaisée des ressorts de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième \n",
      "=============\n",
      "de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième conscience. À l'occasion de la fête de la science, j'aurai le plaisir d'en débattre sans préjugé aux côtés du mathématicien et philosophe Daniel Andler, de la professeur en intelligence artificielle et chercheuse Laurence Devillers et du philosophe Valentin Husson. [Narrateur Radio]: France Culture, sans préjugé. [Nathan Devers]: Nathan Devert. Bonjour Laurence Devillers. [Laurence Devillers]: Bonjour. [Nathan Devers]: Vous êtes professeur en intelligence artificielle à Sorbonne Université, chercheuse au CNRS, auteur de \"L'IA Ange ou Démon\" paru en 2025 aux éditions du Seuil et présidente de la Fondation Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences \n",
      "=============\n",
      "Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences morales et politiques et auteur de \"Intelligence artificielle, intelligence humaine, la double énigme\" aux éditions Gallimard et bonjour Valentin Husson. Vous êtes philosophe et auteur de \"Folle, Ressentimentale, petite philosophie des trolls\" chez philosophie Magazine éditeur qui vient de paraître. Alors pour commencer cette cette discussion sur l'intelligence artificielle, je voulais vous soumettre une histoire qui a eu lieu récemment en mars 2025. Le nouvel Obs a décidé d'organiser un concours littéraire entre deux auteurs entre guillemets. Alors le premier était Hervé Le Tellier prix Goncourt 2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre \n",
      "=============\n",
      "2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre guillemets de rédiger une nouvelle et puis avec la première phrase qui était indiquée c'était quelqu'un qui découvrait un cadavre et la dernière phrase de la nouvelle aussi. Hervé Le Tellier a rendu sa copie, ChatGPT aussi et de l'aveu même de Hervé Le Tellier il a dit franchement, je suis absolument bluffé par la créativité littéraire entre guillemets de ChatGPT, peut-être même que ChatGPT m'a battu que la nouvelle qui a été rendue par l'intelligence artificielle était plus drôle, plus originale, plus vive que celle que j'ai écrite et peut-être donc que ça inaugure un monde où les écrivains seront moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus \n",
      "=============\n",
      "moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus propre la créativité ? [Daniel Andler]: je ne le pense pas mais je pense que c'est pas original de pas le penser. \n",
      "=============\n",
      "[Nathan Devers]: France Culture. Sans préjugés. Natacha Devers. Comment expliquer les progrès phénoménaux que semble avoir accomplis l'intelligence artificielle au cours de ces dernières années ? Depuis l'apparition de ChatGPT en novembre 2022, rapidement suivi par d'autres agents conversationnels. Cette révolution technologique aux multiples aspects, paraît désormais capable d'exécuter de nombreuses tâches intellectuelles sur lesquelles l'esprit humain pensait jusqu'alors exercer un monopole. Écrire des articles, synthétiser des documents, traiter des données dans n'importe quel domaine, diagnostiquer une maladie, rédiger une dissertation, ou pourquoi pas un scénario de film. Non contente de révolutionner le monde du travail, ses prouesses stupéfiantes de la technique soulèvent une interrogation majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans \n",
      "=============\n",
      "majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans n'importe quelle machine, voir, comme s'inquiètent ou exultent certains, que l'IA sera un jour en mesure de remplacer notre conscience. À moins qu'il ne faille poser cette question à l'envers. Comment se fait-il que la machine puisse imiter les œuvres de notre esprit ? Comment est-il possible en d'autres termes que notre vie mentale se révèle comme mécanisable au même titre que nos facultés manuelles. L'intelligence artificielle ne doit-elle pas sa capacité d'imitation au fait qu'elle a été théorisée, inventée, développée d'après une certaine représentation, peut-être incomplète ou biaisée des ressorts de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième \n",
      "=============\n",
      "de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième conscience. À l'occasion de la fête de la science, j'aurai le plaisir d'en débattre sans préjugé aux côtés du mathématicien et philosophe Daniel Andler, de la professeur en intelligence artificielle et chercheuse Laurence Devillers et du philosophe Valentin Husson. [Narrateur Radio]: France Culture, sans préjugé. [Nathan Devers]: Nathan Devert. Bonjour Laurence Devillers. [Laurence Devillers]: Bonjour. [Nathan Devers]: Vous êtes professeur en intelligence artificielle à Sorbonne Université, chercheuse au CNRS, auteur de \"L'IA Ange ou Démon\" paru en 2025 aux éditions du Seuil et présidente de la Fondation Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences \n",
      "=============\n",
      "Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences morales et politiques et auteur de \"Intelligence artificielle, intelligence humaine, la double énigme\" aux éditions Gallimard et bonjour Valentin Husson. Vous êtes philosophe et auteur de \"Folle, Ressentimentale, petite philosophie des trolls\" chez philosophie Magazine éditeur qui vient de paraître. Alors pour commencer cette cette discussion sur l'intelligence artificielle, je voulais vous soumettre une histoire qui a eu lieu récemment en mars 2025. Le nouvel Obs a décidé d'organiser un concours littéraire entre deux auteurs entre guillemets. Alors le premier était Hervé Le Tellier prix Goncourt 2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre \n",
      "=============\n",
      "2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre guillemets de rédiger une nouvelle et puis avec la première phrase qui était indiquée c'était quelqu'un qui découvrait un cadavre et la dernière phrase de la nouvelle aussi. Hervé Le Tellier a rendu sa copie, ChatGPT aussi et de l'aveu même de Hervé Le Tellier il a dit franchement, je suis absolument bluffé par la créativité littéraire entre guillemets de ChatGPT, peut-être même que ChatGPT m'a battu que la nouvelle qui a été rendue par l'intelligence artificielle était plus drôle, plus originale, plus vive que celle que j'ai écrite et peut-être donc que ça inaugure un monde où les écrivains seront moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus \n",
      "=============\n",
      "moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus propre la créativité ? [Daniel Andler]: je ne le pense pas mais je pense que c'est pas original de pas le penser. \n",
      "=============\n",
      "[Nathan Devers]: France Culture. Sans préjugés. Natacha Devers. Comment expliquer les progrès phénoménaux que semble avoir accomplis l'intelligence artificielle au cours de ces dernières années ? Depuis l'apparition de ChatGPT en novembre 2022, rapidement suivi par d'autres agents conversationnels. Cette révolution technologique aux multiples aspects, paraît désormais capable d'exécuter de nombreuses tâches intellectuelles sur lesquelles l'esprit humain pensait jusqu'alors exercer un monopole. Écrire des articles, synthétiser des documents, traiter des données dans n'importe quel domaine, diagnostiquer une maladie, rédiger une dissertation, ou pourquoi pas un scénario de film. Non contente de révolutionner le monde du travail, ses prouesses stupéfiantes de la technique soulèvent une interrogation majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans \n",
      "=============\n",
      "majeure dans le domaine de la philosophie de l'esprit. Faut-il en déduire que l'intelligence, n'étant pas le propre d'un cerveau biologique et encore moins d'une âme, peut s'implémenter dans n'importe quelle machine, voir, comme s'inquiètent ou exultent certains, que l'IA sera un jour en mesure de remplacer notre conscience. À moins qu'il ne faille poser cette question à l'envers. Comment se fait-il que la machine puisse imiter les œuvres de notre esprit ? Comment est-il possible en d'autres termes que notre vie mentale se révèle comme mécanisable au même titre que nos facultés manuelles. L'intelligence artificielle ne doit-elle pas sa capacité d'imitation au fait qu'elle a été théorisée, inventée, développée d'après une certaine représentation, peut-être incomplète ou biaisée des ressorts de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième \n",
      "=============\n",
      "de notre conscience, si bien que les miracles de l'IA nous inviteraient à explorer à nouveau frais l'irréductible singularité de notre propre pensée. L'intelligence artificielle, notre deuxième conscience. À l'occasion de la fête de la science, j'aurai le plaisir d'en débattre sans préjugé aux côtés du mathématicien et philosophe Daniel Andler, de la professeur en intelligence artificielle et chercheuse Laurence Devillers et du philosophe Valentin Husson. [Narrateur Radio]: France Culture, sans préjugé. [Nathan Devers]: Nathan Devert. Bonjour Laurence Devillers. [Laurence Devillers]: Bonjour. [Nathan Devers]: Vous êtes professeur en intelligence artificielle à Sorbonne Université, chercheuse au CNRS, auteur de \"L'IA Ange ou Démon\" paru en 2025 aux éditions du Seuil et présidente de la Fondation Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences \n",
      "=============\n",
      "Blaise Pascal. Bonjour Daniel Andler. [Daniel Andler]: Bonjour. [Nathan Devers]: Vous êtes mathématicien, philosophe, professeur émérite à Sorbonne Université, membre de l'Académie des sciences morales et politiques et auteur de \"Intelligence artificielle, intelligence humaine, la double énigme\" aux éditions Gallimard et bonjour Valentin Husson. Vous êtes philosophe et auteur de \"Folle, Ressentimentale, petite philosophie des trolls\" chez philosophie Magazine éditeur qui vient de paraître. Alors pour commencer cette cette discussion sur l'intelligence artificielle, je voulais vous soumettre une histoire qui a eu lieu récemment en mars 2025. Le nouvel Obs a décidé d'organiser un concours littéraire entre deux auteurs entre guillemets. Alors le premier était Hervé Le Tellier prix Goncourt 2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre \n",
      "=============\n",
      "2020 auteur de du célèbre roman l'Anomalie et le deuxième était l'intelligence artificielle et plus précisément ChatGPT. Le l'objet de ce concours était de demander à l'un comme à l'autre entre guillemets de rédiger une nouvelle et puis avec la première phrase qui était indiquée c'était quelqu'un qui découvrait un cadavre et la dernière phrase de la nouvelle aussi. Hervé Le Tellier a rendu sa copie, ChatGPT aussi et de l'aveu même de Hervé Le Tellier il a dit franchement, je suis absolument bluffé par la créativité littéraire entre guillemets de ChatGPT, peut-être même que ChatGPT m'a battu que la nouvelle qui a été rendue par l'intelligence artificielle était plus drôle, plus originale, plus vive que celle que j'ai écrite et peut-être donc que ça inaugure un monde où les écrivains seront moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus \n",
      "=============\n",
      "moins moins présents que l'intelligence artificielle. Daniel Andler, une telle histoire qu'est-ce qu'elle révèle ? Est-ce qu'elle signifie que l'IA peut battre l'esprit humain dans ce qu'il a de plus propre la créativité ? [Daniel Andler]: je ne le pense pas mais je pense que c'est pas original de pas le penser. \n",
      "=============\n"
     ]
    }
   ],
   "source": [
    "for c in all_docs[\"documents\"]:\n",
    "    print(c, \"\\n=============\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebbb31f",
   "metadata": {},
   "source": [
    "#### Création ou chargement d'un graphe existant:\n",
    "Saisir l'action désirée dans le prompt qui s'affiche en haut du notebook, suivre instructions\n",
    "\n",
    "Par défaut prise en compte des 20 premières pages pour l'exemple, modifier ligne 11 `for doc in docx_docs[:20]:`\n",
    "\n",
    "Si vous voulez charger un graphe déjà crée, retrouver son nom dans le fichier `graphrag_hashes.json`, attribut `Nom du doc`\n",
    "\n",
    "Si vous voulez modifier le LLM utilisé pour la création du graphe ou sa lecture, allez dans `pathrag_retriever.py`, ligne 34 et 35, et prenez un modèle valide sur openrouter (attention à prendre un modèle qui supporte les `structured_outputs`, à filtrer à droite dans la liste des `Supported parameters`)\n",
    "\n",
    "**Important**: renseigner votre clé api openrouter sur le script `pathrag_retriever.py`, ligne 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63b4a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nom de votre graphe est L-IA-notre deuxieme-conscience_sample\n",
      "Génération du hash\n",
      "load hashes\n",
      "Chargement de l'historique de hashage Graph RAG\n",
      "check hash\n",
      "Nouveau document identifié\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PathRAG:Logger initialized for working directory: /home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/77dbce69c6becbc4ccbea21cb8f1bca1c6e7dc6d24c53f6905ab1af9a73e71ec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouveau document identifié\n",
      "77dbce69c6becbc4ccbea21cb8f1bca1c6e7dc6d24c53f6905ab1af9a73e71ec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PathRAG:Load KV llm_response_cache with 0 data\n",
      "INFO:PathRAG:Load KV full_docs with 0 data\n",
      "INFO:PathRAG:Load KV text_chunks with 0 data\n",
      "INFO:PathRAG:Loaded graph from /home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/77dbce69c6becbc4ccbea21cb8f1bca1c6e7dc6d24c53f6905ab1af9a73e71ec/graph_chunk_entity_relation.graphml with 0 nodes, 0 edges\n",
      "INFO:nano-vectordb:Load (0, 768) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': '/home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/77dbce69c6becbc4ccbea21cb8f1bca1c6e7dc6d24c53f6905ab1af9a73e71ec/vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Load (0, 768) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': '/home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/77dbce69c6becbc4ccbea21cb8f1bca1c6e7dc6d24c53f6905ab1af9a73e71ec/vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Load (1, 768) data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': '/home/chougar/Documents/GitHub/experiments/associatif/IA audiovisuel/RAG/storage/graph_stores/77dbce69c6becbc4ccbea21cb8f1bca1c6e7dc6d24c53f6905ab1af9a73e71ec/vdb_chunks.json'} 1 data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création de la chaîne Graph RAG en cours\n",
      "Temps estimé: 67 secondes\n",
      "Consommation de tokens estimée: 14275 tokens (90% input / 10% output)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:PathRAG:[New Docs] inserting 1 docs\n",
      "Chunking documents: 100%|██████████| 1/1 [00:01<00:00,  1.13s/doc]\n",
      "INFO:PathRAG:[New Chunks] inserting 1 chunks\n",
      "INFO:PathRAG:Inserting 1 vectors to chunks\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.06batch/s]\n",
      "INFO:PathRAG:[Entity Extraction]...\n",
      "Extracting entities from chunks:   0%|          | 0/1 [00:00<?, ?chunk/s]INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠙ Processed 1 chunks, 25 entities(duplicated), 12 relations(duplicated)\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting entities from chunks: 100%|██████████| 1/1 [01:09<00:00, 69.94s/chunk]\n",
      "INFO:PathRAG:Inserting entities into storage...\n",
      "Inserting entities: 100%|██████████| 25/25 [00:00<00:00, 1419.93entity/s]\n",
      "INFO:PathRAG:Inserting relationships into storage...\n",
      "Inserting relationships: 100%|██████████| 12/12 [00:00<00:00, 2034.34relationship/s]\n",
      "INFO:PathRAG:Inserting 25 vectors to entities\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  1.11batch/s]\n",
      "INFO:PathRAG:Inserting 12 vectors to relationships\n",
      "Generating embeddings: 100%|██████████| 1/1 [00:00<00:00,  2.29batch/s]\n",
      "INFO:PathRAG:Writing graph with 25 nodes, 12 edges\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Création de la chaîne Graph RAG en 93 secondes\n",
      "Création du visuel du graphe de connaissances\n"
     ]
    }
   ],
   "source": [
    "# appliquer nest_asyncio uniquement sur notebook pour corriger l'erreur de loop event\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# remetre à plat le text\n",
    "filename=\"audio-text.txt\"\n",
    "loader = UnstructuredLoader(filename)\n",
    "\n",
    "txt_docs = loader.load()\n",
    "text=\"\"\n",
    "for doc in txt_docs:\n",
    "    text+=doc.page_content\n",
    "\n",
    "\n",
    "r=input(\"Saisir 'C' pour créer un nouveau graphe, 'L' pour charger un graphe existant\")\n",
    "\n",
    "# créer un nouveau graphe\n",
    "messages=None\n",
    "if r=='C':\n",
    "    doc_name_graph=input('Saisir un nom unique pour votre graphe')\n",
    "    print(f\"Le nom de votre graphe est {doc_name_graph}\")\n",
    "    messages= create_graphdb(\n",
    "        text=text, \n",
    "        doc_name=doc_name_graph, # il faut donner un nom unique permettant d'identifier et charger le graph les prochaines fois\n",
    "    )\n",
    "# charger un graphe existant\n",
    "elif r=='L':\n",
    "    doc_name_graph=input('Saisir le nom du graphe à charger')\n",
    "    print(f\"Le nom de votre graphe est {doc_name_graph}\")\n",
    "\n",
    "    messages=load_existing_graphdb(doc_name_graph)\n",
    "else:\n",
    "    print('Option invalide')\n",
    "\n",
    "\n",
    "\n",
    "if messages:\n",
    "    pipeline_args={}\n",
    "    for feedback in messages:\n",
    "        if isinstance(feedback, str):\n",
    "            print(feedback)\n",
    "        elif isinstance(feedback, dict):\n",
    "            pipeline_args[f\"graphrag_pipeline_{doc_name_graph}\"]=feedback[\"pipeline_args\"]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6de14e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:PathRAG:kw_prompt result:\n",
      "INFO:PathRAG:```json\n",
      "{\n",
      "  \"high_level_keywords\": [\"Analyse textuelle\", \"Thèmes principaux\", \"Questions de discussion\"],\n",
      "  \"low_level_keywords\": [\"Identification des thèmes\", \"Compréhension de texte\", \"Questions ouvertes\", \"Lecture analytique\"]\n",
      "}\n",
      "```\n",
      "INFO:PathRAG:Local query uses 25 entites, 15 relations, 1 text units\n",
      "INFO:PathRAG:Global query uses 17 entites, 12 relations, 1 text units\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "response all ready\n",
      "## Main Themes and Potential Questions from the Provided Text\n",
      "\n",
      "The core of the text revolves around the burgeoning field of Artificial Intelligence (AI) and its profound implications for humanity, specifically focusing on creativity, consciousness, and the very definition of intelligence itself.  Several key themes emerge, interwoven through discussions of specific individuals, organizations, and events.\n",
      "\n",
      "**Central Themes:**\n",
      "\n",
      "*   **AI and Creativity:** A significant theme is the ability of AI, demonstrated by ChatGPT, to engage in creative endeavors like writing. The literary competition between Hervé Le Tellier and ChatGPT, as highlighted by *Le Nouvel Obs*, serves as a focal point for exploring whether AI can truly *create* or merely *simulate* creativity.  This discussion is underpinned by Le Tellier’s own assessment that ChatGPT may have surpassed his own literary efforts, prompting questions about the future role of human artists.\n",
      "*   **The Nature of Intelligence:**  The text probes the fundamental question of what constitutes intelligence.  Are intelligence and consciousness exclusive to biological brains, or can they be replicated in machines? Figures like Daniel Andler and Laurence Devillers contribute to this debate, considering whether AI’s imitative abilities reveal something about the mechanics of human thought or represent a fundamentally different phenomenon.\n",
      "*   **Philosophical and Ethical Implications of AI:** The discussion extends beyond technical capabilities to explore the ethical and philosophical ramifications of advanced AI. Is AI a tool to be utilized, or a potential replacement for human capabilities, even consciousness? This is reflected in the titles of books by the contributors, such as Laurence Devillers’ *L’IA Ange ou Démon* (AI – Angel or Demon) and Daniel Andler’s *Intelligence artificielle, intelligence humaine, la double énigme* (Artificial intelligence, human intelligence, the double enigma).\n",
      "*   **The Role of Research and Academia:** The text emphasizes the involvement of academic institutions like Sorbonne Université and research organizations like CNRS in the development and critical analysis of AI. Individuals affiliated with these institutions – Devillers and Andler – are positioned as key voices in the dialogue.\n",
      "\n",
      "**Potential Questions Arising from the Text:**\n",
      "\n",
      "The text naturally lends itself to a multitude of questions, spanning technical, philosophical, and societal domains:\n",
      "\n",
      "*   **Can AI truly be creative, or is it simply a sophisticated form of pattern recognition and imitation?** This question is central to the competition narrative and prompts consideration of the origins and nature of creativity.\n",
      "*   **What are the potential consequences for human employment and the arts if AI continues to advance at its current pace?** The perceived threat to writers posed by ChatGPT raises concerns about broader economic and cultural shifts.\n",
      "*   **How might our understanding of human consciousness be reshaped by the development of increasingly intelligent machines?** AI’s ability to mimic human thought processes may require a reevaluation of what makes human consciousness unique.\n",
      "*   **What ethical guidelines should govern the development and deployment of AI to ensure its responsible use?**  The “angel or demon” framing suggests the need for careful consideration of AI's potential risks and benefits.\n",
      "*   **What is the role of academia and research institutions in guiding the responsible development of AI, and ensuring open discussion and critical assessment?** The prominence of academics suggests a key role for these institutions in shaping the conversation around AI.\n",
      "*    **How do the books written by the individuals involved (Devillers, Andler, Husson) contribute to the broader conversation about AI?** Exploring these works would provide deeper insight into their individual perspectives.\n",
      "*   **What was the outcome of the literary competition between Hervé Le Tellier and ChatGPT?** While the text sets the scene, it doesn’t reveal the results.\n",
      "\n",
      "\n",
      "\n",
      "The dialogue featured in the source material, particularly the radio program on France Culture, suggests an ongoing, multifaceted debate regarding all of these areas."
     ]
    }
   ],
   "source": [
    "from PathRAG import QueryParam\n",
    "import asyncio\n",
    "\n",
    "def stream_pathRAG_response(stream_resp):\n",
    "    async def stream_response():        \n",
    "        # Process the async generator\n",
    "        async for chunk in stream_resp:\n",
    "            print(chunk or \"\", end=\"\")\n",
    "\n",
    "\n",
    "    # Run in Streamlit's existing event loop\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(stream_response())\n",
    "\n",
    "# question=\"résume ce texte dans sa langue source\"\n",
    "question = \"Quels sont les principaux thèmes de ce texte et les questions qui peuvent être posées ?\"\n",
    "\n",
    "resp=pipeline_args[f\"graphrag_pipeline_{doc_name_graph}\"][\"rag\"].query(query= question, param=QueryParam(mode=\"hybrid\", stream=True))\n",
    "\n",
    "stream_pathRAG_response(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f595f8",
   "metadata": {},
   "source": [
    "Renseigner votre clé d'api sur la ligne 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84137027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OllamaEmbeddings\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from langchain.retrievers import TFIDFRetriever\n",
    "from langchain.schema.document import Document\n",
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "import json\n",
    "import re\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\"/home/chougar/Documents/GitHub/experiments/.env\")\n",
    "\n",
    "API_KEY_REF=os.getenv(\"OPENROUTER_API_KEY\")\n",
    "\n",
    "\n",
    "class RAG_hybrid():\n",
    "    def __init__(self, model):\n",
    "        self.model=model\n",
    "        self.retrieved_docs=[]\n",
    "        self.semantic_retriever_topK=10\n",
    "        self.sparse_retriever_topK=10\n",
    "        self.history=[]\n",
    "        self.llm_client = AsyncOpenAI(\n",
    "            base_url=\"https://openrouter.ai/api/v1\",\n",
    "            api_key=API_KEY_REF,\n",
    "        )\n",
    "        self.reranker_llm=\"mistralai/mistral-small-3.1-24b-instruct\"\n",
    "        self.reranker_score_thresh=5\n",
    "        self.reranked_doc=[]\n",
    "\n",
    "    def semanticRetriever(self):\n",
    "        # 1. Semantic Retriever (Chroma + OllamaEmbeddings)\n",
    "        embeddings = OllamaEmbeddings(model=\"embeddinggemma\")\n",
    "        chroma_db = Chroma(\n",
    "            persist_directory=f'./storage/vector_scores/{doc_name_hybrid.replace(\" \",\"_\")}',\n",
    "            collection_name=doc_name_hybrid.replace(\" \",\"_\"),\n",
    "            embedding_function=embeddings\n",
    "        )\n",
    "\n",
    "        semantic_retriever=chroma_db.as_retriever(search_type=\"mmr\", k=self.semantic_retriever_topK)\n",
    "\n",
    "        self.chroma_db=chroma_db\n",
    "        self.semantic_retriever=semantic_retriever\n",
    "    \n",
    "    def sparseRetriever(self):\n",
    "        # 2. Sparse Retriever (TF-IDF)\n",
    "\n",
    "        # Récupérer TOUS les documents depuis Chroma\n",
    "        all_data = self.chroma_db.get(include=[\"documents\", \"metadatas\"])\n",
    "\n",
    "        # Convertir en liste de `Document` objects pour LangChain\n",
    "        docs = [\n",
    "            Document(page_content=text, metadata=meta or {})  # <-- Si meta est None, on met {}\n",
    "            for text, meta in zip(all_data[\"documents\"], all_data[\"metadatas\"])\n",
    "        ]\n",
    "\n",
    "        # Créer le retriever TF-IDF\n",
    "        sparse_retriever = TFIDFRetriever.from_documents(\n",
    "            documents=docs,\n",
    "            k=self.sparse_retriever_topK,\n",
    "            tfidf_params={\"min_df\": 1, \"ngram_range\": (1, 2)}\n",
    "        )\n",
    "\n",
    "        self.sparse_retriever= sparse_retriever\n",
    "    \n",
    "    def ensembleRetriever(self):\n",
    "        # 3. Ensemble Retriever (Semantic + Sparse)\n",
    "        ensemble_retriever = EnsembleRetriever(\n",
    "            retrievers=[self.semantic_retriever, self.sparse_retriever],\n",
    "            weights=[0.5, 0.5]\n",
    "        )\n",
    "\n",
    "        self.ensemble_retriever=ensemble_retriever\n",
    "\n",
    "    async def reranker(self, results, query):\n",
    "\n",
    "\n",
    "        async def llm_eval(doc, query):\n",
    "            system_prompt=\"\"\"\n",
    "                You're an expert assistant in reranking documents against a question.\n",
    "                Your role is to compare the question with a document and give a score from 0 to 10, where:\n",
    "                0=document out of context, unable to answer the question\n",
    "                10=highly relevant document, able to answer the question\n",
    "                                \n",
    "                The expected final output is the score in json format\n",
    "                Example:\n",
    "                ```json{\"score\": 5}```\n",
    "                \n",
    "                Always end your answer with this format                \n",
    "            \"\"\"            \n",
    "            response = await self.llm_client.chat.completions.create(\n",
    "                model=self.reranker_llm,\n",
    "                messages=[\n",
    "                    {\"role\": \"system\", \"content\": system_prompt},\n",
    "                    {\"role\": \"user\", \"content\": f\"La question est: {query}\\n Le document à évaluer est le suivant\\n: {doc}\" }\n",
    "                ],\n",
    "                temperature=0,\n",
    "            )\n",
    "            # Post-process to extract only the JSON part if extra text is present\n",
    "            content = response.choices[0].message.content\n",
    "            # Try to extract the JSON block if the model adds extra text\n",
    "            match = re.search(r\"\\{.*?\\}\", content, re.DOTALL)\n",
    "            if match:\n",
    "                content = match.group(0)\n",
    "\n",
    "            # extract score\n",
    "            score=None\n",
    "            try:\n",
    "                score=content.replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "                \n",
    "                score= json.loads(score)\n",
    "                score=score[\"score\"]\n",
    "            except Exception as e:\n",
    "                print(e)                \n",
    "            \n",
    "            return {\"content\": doc, \"score\": score}\n",
    "\n",
    "\n",
    "        tasks=[llm_eval(doc.page_content, query) for doc in results]\n",
    "        scored_docs= await asyncio.gather(*tasks)\n",
    "        i=1\n",
    "\n",
    "        for doc in scored_docs:\n",
    "          \n",
    "            print(f'chunk {i} score: {doc[\"score\"]}')\n",
    "            i+=1\n",
    "\n",
    "        filtred_docs=[d for d in scored_docs if d[\"score\"]>=self.reranker_score_thresh]\n",
    "        # print(f\"scored docs; \\n{scored_docs}\")\n",
    "        self.reranked_doc=filtred_docs\n",
    "\n",
    "        return filtred_docs\n",
    "\n",
    "    async def ask_llm(self, query):\n",
    "        # 5. Final processing step with an LLM (e.g., OpenAI via OpenRouter)\n",
    "\n",
    "        # init retrievers\n",
    "        self.semanticRetriever()\n",
    "        self.sparseRetriever()\n",
    "        self.ensembleRetriever()\n",
    "\n",
    "        # retrieve relevant docs\n",
    "        results = self.ensemble_retriever.get_relevant_documents(query)\n",
    "        print(f\"Nb of retrieved docs: {len(results)}\")\n",
    "\n",
    "        # rerank\n",
    "        scored_results=await self.reranker(results, query)\n",
    "        \n",
    "        # Concatenate retrieved documents for context\n",
    "        context = \"\\n\".join([f\"Fragment: \\n{doc['content']}\\n\" for doc in scored_results])\n",
    "\n",
    "        print(f\"Context lenght: {len(context.split(' '))} words\")\n",
    "        llm_prompt = f\"\"\"\n",
    "            Answer the question based **only** on the provided context.  \n",
    "\n",
    "            - If the context contains enough information to provide a complete or partial answer, use it to formulate a detailed and factual response.  \n",
    "            - If the context lacks relevant information, respond with: \"I don't know.\"  \n",
    "\n",
    "            ### **Context:**  \n",
    "            {context}  \n",
    "\n",
    "            ### **Question:**  \n",
    "            {query}  \n",
    "\n",
    "            ### **Answer:**  \n",
    "            Provide a clear, factual, and well-structured response based on the available context. Avoid speculation or adding external knowledge.  \n",
    "        \"\"\"\n",
    "\n",
    "        llm_completion = await self.llm_client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are an expert in document Q/A and document synthesis\"},\n",
    "                {\"role\": \"user\", \"content\": llm_prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            stream=True\n",
    "        )\n",
    "\n",
    "        final_answer = \"\"\n",
    "        print(\"Réponse:\\n=========\")\n",
    "        async for chunk in llm_completion:\n",
    "            if hasattr(chunk.choices[0].delta, \"content\") and chunk.choices[0].delta.content:\n",
    "                final_answer += chunk.choices[0].delta.content\n",
    "                print(chunk.choices[0].delta.content, end=\"\", flush=True)\n",
    "        \n",
    "        self.history+=[\n",
    "            {\"role\": \"user\", 'content': query},\n",
    "            {\"role\": \"assistant\", \"content\": final_answer}\n",
    "        ]\n",
    "        \n",
    "        return final_answer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a224490",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientStartEvent: capture() takes 1 positional argument but 3 were given\n",
      "ERROR:chromadb.telemetry.product.posthog:Failed to send telemetry event ClientCreateCollectionEvent: capture() takes 1 positional argument but 3 were given\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nb of retrieved docs: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 1 score: 3\n",
      "chunk 2 score: 7\n",
      "chunk 3 score: 8\n",
      "chunk 4 score: 4\n",
      "chunk 5 score: 7\n",
      "Context lenght: 444 words\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://openrouter.ai/api/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Réponse:\n",
      "=========\n",
      "### **Principaux thèmes du texte :**\n",
      "\n",
      "1. **Comparaison entre l'intelligence humaine et l'intelligence artificielle (IA)** :\n",
      "   - Le texte compare les capacités créatives de l'écrivain Hervé Le Tellier et de l'IA ChatGPT, notamment dans la rédaction de nouvelles.\n",
      "   - Il souligne la capacité de l'IA à produire des œuvres littéraires originales et drôles, remettant en question la supériorité de l'esprit humain dans ce domaine.\n",
      "\n",
      "2. **Progrès de l'IA et ses implications** :\n",
      "   - Le texte évoque les avancées rapides de l'IA, notamment depuis l'apparition de ChatGPT en novembre 2022.\n",
      "   - Il mentionne les nombreuses tâches intellectuelles que l'IA peut désormais accomplir, telles que l'écriture d'articles, la synthèse de documents, le diagnostic de maladies, et la rédaction de scénarios de films.\n",
      "\n",
      "3. **Philosophie de l'esprit et la nature de l'intelligence** :\n",
      "   - Le texte aborde la question de savoir si l'intelligence peut être implémentée dans des machines, remettant en question l'idée que l'intelligence est exclusive aux cerveaux biologiques ou à une âme.\n",
      "   - Il explore également la possibilité que l'IA puisse un jour remplacer la conscience humaine.\n",
      "\n",
      "4. **Singularité de la pensée humaine** :\n",
      "   - Le texte suggère que les capacités de l'IA à imiter les œuvres humaines pourraient inviter à une réévaluation de la singularité de la pensée humaine.\n",
      "   - Il pose la question de savoir si l'IA doit sa capacité d'imitation à une représentation incomplète ou biaisée des mécanismes de la conscience humaine.\n",
      "\n",
      "### **Questions qui peuvent être posées :**\n",
      "\n",
      "1. **Comparaison entre l'IA et l'esprit humain** :\n",
      "   - L'IA peut-elle surpasser l'esprit humain dans des domaines créatifs comme la littérature ?\n",
      "   - Quelles sont les implications de la capacité de l'IA à produire des œuvres originales et drôles ?\n",
      "\n",
      "2. **Progrès de l'IA et ses applications** :\n",
      "   - Quelles sont les tâches intellectuelles que l'IA peut accomplir et comment cela affecte-t-il le monde du travail ?\n",
      "   - Comment l'IA peut-elle être utilisée dans des domaines tels que la médecine, l'écriture, et la création de scénarios de films ?\n",
      "\n",
      "3. **Philosophie de l'esprit et l'intelligence artificielle** :\n",
      "   - L'intelligence peut-elle être implémentée dans des machines, ou est-elle exclusive aux cerveaux biologiques ?\n",
      "   - L'IA peut-elle un jour remplacer la conscience humaine ?\n",
      "\n",
      "4. **Singularité de la pensée humaine** :\n",
      "   - Comment l'IA imite-t-elle les œuvres humaines, et que cela révèle-t-il sur la nature de la pensée humaine ?\n",
      "   - Les capacités de l'IA à imiter les œuvres humaines invitent-elles à une réévaluation de la singularité de la pensée humaine ?"
     ]
    }
   ],
   "source": [
    "rag_hybrid=RAG_hybrid(model=\"mistralai/mistral-small-3.2-24b-instruct\")\n",
    "# 4. Ask a question\n",
    "question = \"Quels sont les principaux thèmes de ce texte et les questions qui peuvent être posées ?\"\n",
    "results = await rag_hybrid.ask_llm(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pathrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
